{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "import scipy.io as sci\n",
    "%matplotlib inline\n",
    "def chunk(xs, n):\n",
    "    ys = list(xs)\n",
    "    random.shuffle(ys)\n",
    "    size = len(ys) // n\n",
    "    leftovers= ys[size*n:]\n",
    "    for c in xrange(n):\n",
    "        if leftovers:\n",
    "           extra= [ leftovers.pop() ] \n",
    "        else:\n",
    "           extra= []\n",
    "        yield ys[c*size:(c+1)*size] + extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def common_neighbours(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = mat[e[0]][e[1]]\n",
    "    return edgesWithScore \n",
    "\n",
    "def salton_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(np.sqrt(j * k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def jaccard_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        if nx.degree(i, e[0]) != 0 or nx.degree(i, e[1]) != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(len(set(i[e[0]])|set(i[e[1]])))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def sorensen_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 or k != 0:\n",
    "            edgesWithScore[e] = 2*float(mat[e[0]][e[1]])/float(j + k)\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def hub_promoted_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(min(j, k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def hub_depressed_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 or k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(max(j, k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def LHN1_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(j * k)\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def preferential_attachment_index(sub):\n",
    "    i = sub\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = nx.degree(i, e[0]) * nx.degree(i, e[1])\n",
    "    return edgesWithScore\n",
    "\n",
    "def adamic_adar_index(sub):\n",
    "    i = sub\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = np.sum(1/np.log(nx.degree(i, sorted(nx.common_neighbors(i, e[0], e[1]))).values()))\n",
    "    return edgesWithScore\n",
    "\n",
    "def resource_allocation_index(sub):\n",
    "    i = sub\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = np.sum(1/np.array(\n",
    "                nx.degree(i, sorted(nx.common_neighbors(i, e[0], e[1]))).values()).astype(float))\n",
    "    return edgesWithScore\n",
    "\n",
    "def katz_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    ide = np.identity(len(mat))\n",
    "    beta = (1/float(max(np.linalg.eig(mat)[0])))/2\n",
    "    sim = np.linalg.inv(ide - beta*mat) - ide\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def lhn2_index(sub, phi = 0.1):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    ide = np.identity(len(mat))\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = 0\n",
    "    if np.linalg.det(dma) != 0:\n",
    "        lambd = float(max(np.linalg.eig(mat)[0]))\n",
    "        sim = (2 * i.number_of_edges() * lambd * np.linalg.inv(dma)).dot(np.linalg.inv(\n",
    "        ide - (phi/lambd) * mat)).dot(np.linalg.inv(dma))\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def act_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    sim = np.linalg.pinv(dma - mat)\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        if sim[e[0]][e[0]] + sim[e[1]][e[1]] - 2*sim[e[0]][e[1]] != 0:\n",
    "            edgesWithScore[e] = 1/float(sim[e[0]][e[0]] + sim[e[1]][e[1]] - 2*sim[e[0]][e[1]])\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def cbl_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    sim = np.linalg.pinv(dma - mat)\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        if sim[e[0]][e[0]] * sim[e[1]][e[1]] != 0:\n",
    "            edgesWithScore[e] = float(sim[e[0]][e[1]])/np.sqrt(sim[e[0]][e[0]] * sim[e[1]][e[1]])\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def rwr_index(sub, c = 0.5):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    sim = np.linalg.pinv(dma - mat)\n",
    "    ide = np.identity(len(mat))\n",
    "    pmt = np.identity(len(mat))\n",
    "    es = []\n",
    "    for a in i.nodes():\n",
    "        e = np.zeros(len(mat))\n",
    "        e[a] = 1\n",
    "        es.append(e)\n",
    "        for b in i.nodes():\n",
    "            try:\n",
    "                nx.shortest_path_length(i, source = a, target = b)\n",
    "            except:\n",
    "                pmt[a][b] = 0\n",
    "            else:\n",
    "                if nx.degree(i, a) != 0:\n",
    "                    pmt[a][b] = 1/float(nx.degree(i, a))\n",
    "                else:\n",
    "                    pmt[a][b] = 0\n",
    "    es = np.array(es)\n",
    "    qs = []\n",
    "    for a in i.nodes():\n",
    "        if np.linalg.det(ide - c*np.transpose(pmt)) != 0:\n",
    "            q = ((1 - c)*np.linalg.inv(ide - c*np.transpose(pmt))).dot(es[a])\n",
    "        else:\n",
    "            q = es[a]\n",
    "        qs.append(q)\n",
    "    qs = np.array(qs)\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = qs[e[0]][e[1]] + qs[e[1]][e[0]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def matrix_forest_index(sub, alpha = 1):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    ide = np.identity(len(mat))\n",
    "    sim = np.linalg.inv(ide + alpha*(dma - mat))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def predict_nodes(G, nfolds = 10):\n",
    "    df = pd.DataFrame()\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    es = nx.non_edges(subs[0])\n",
    "    edges = []\n",
    "    y = {}\n",
    "    for e in es:\n",
    "        edges.append(e)\n",
    "        check = 0\n",
    "        if e in folds[0]:\n",
    "            check = 1\n",
    "        y[e] = check\n",
    "    df['Edges'] = edges\n",
    "    df['y'] = df['Edges'].map(y.get)\n",
    "    df['CN'] = df['Edges'].map(common_neighbours(subs[0]).get)\n",
    "    df['SaI'] = df['Edges'].map(salton_index(subs[0]).get)\n",
    "    df['JI'] = df['Edges'].map(jaccard_index(subs[0]).get)\n",
    "    df['SoI'] = df['Edges'].map(sorensen_index(subs[0]).get)\n",
    "    df['HPI'] = df['Edges'].map(hub_promoted_index(subs[0]).get)\n",
    "    df['HDI'] = df['Edges'].map(hub_depressed_index(subs[0]).get)\n",
    "    df['LHN1'] = df['Edges'].map(LHN1_index(subs[0]).get)\n",
    "    df['PAI'] = df['Edges'].map(preferential_attachment_index(subs[0]).get)\n",
    "    df['AAI'] = df['Edges'].map(adamic_adar_index(subs[0]).get)\n",
    "    df['RAI'] = df['Edges'].map(resource_allocation_index(subs[0]).get)\n",
    "    df['KzI'] = df['Edges'].map(katz_index(subs[0]).get)\n",
    "    df['LHN2'] = df['Edges'].map(lhn2_index(subs[0]).get)\n",
    "    df['ACT'] = df['Edges'].map(act_index(subs[0]).get)\n",
    "    df['CBL'] = df['Edges'].map(cbl_index(subs[0]).get)\n",
    "    df['RWR'] = df['Edges'].map(rwr_index(subs[0]).get)\n",
    "    df['MFI'] = df['Edges'].map(matrix_forest_index(subs[0]).get)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn import lda\n",
    "from sklearn import qda\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "def run_10_fold_on_G(G, nfolds = 10):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    frames = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        sub = graph.copy()\n",
    "        df = pd.DataFrame()\n",
    "        es = nx.non_edges(sub)\n",
    "        edges = []\n",
    "        y = {}\n",
    "        for e in es:\n",
    "            edges.append(e)\n",
    "            if e in folds[i]:\n",
    "                y[e] = 1\n",
    "            else:\n",
    "                y[e] = 0\n",
    "        df['Edges'] = edges\n",
    "        df['y'] = df['Edges'].map(y.get)\n",
    "        df['CN'] = df['Edges'].map(common_neighbours(sub).get)\n",
    "        df['SaI'] = df['Edges'].map(salton_index(sub).get)\n",
    "        df['JI'] = df['Edges'].map(jaccard_index(sub).get)\n",
    "        df['SoI'] = df['Edges'].map(sorensen_index(sub).get)\n",
    "        df['HPI'] = df['Edges'].map(hub_promoted_index(sub).get)\n",
    "        df['HDI'] = df['Edges'].map(hub_depressed_index(sub).get)\n",
    "        df['LHN1'] = df['Edges'].map(LHN1_index(sub).get)\n",
    "        df['PAI'] = df['Edges'].map(preferential_attachment_index(sub).get)\n",
    "        df['AAI'] = df['Edges'].map(adamic_adar_index(sub).get)\n",
    "        df['RAI'] = df['Edges'].map(resource_allocation_index(sub).get)\n",
    "        df['KzI'] = df['Edges'].map(katz_index(sub).get)\n",
    "        df['LHN2'] = df['Edges'].map(lhn2_index(sub).get)\n",
    "        df['ACT'] = df['Edges'].map(act_index(sub).get)\n",
    "        df['CBL'] = df['Edges'].map(cbl_index(sub).get)\n",
    "        df['RWR'] = df['Edges'].map(rwr_index(sub).get)\n",
    "        df['MFI'] = df['Edges'].map(matrix_forest_index(sub).get)\n",
    "        df = df.fillna(0)\n",
    "        frames.append(df)\n",
    "    return frames, folds\n",
    "\n",
    "def run_indices_on_compl(sub):\n",
    "    df = pd.DataFrame()\n",
    "    es = nx.non_edges(sub)\n",
    "    edges = []\n",
    "    for e in es:\n",
    "        edges.append(e)\n",
    "    df['Edges'] = edges\n",
    "    df['CN'] = df['Edges'].map(common_neighbours(sub).get)\n",
    "    df['SaI'] = df['Edges'].map(salton_index(sub).get)\n",
    "    df['JI'] = df['Edges'].map(jaccard_index(sub).get)\n",
    "    df['SoI'] = df['Edges'].map(sorensen_index(sub).get)\n",
    "    df['HPI'] = df['Edges'].map(hub_promoted_index(sub).get)\n",
    "    df['HDI'] = df['Edges'].map(hub_depressed_index(sub).get)\n",
    "    df['LHN1'] = df['Edges'].map(LHN1_index(sub).get)\n",
    "    df['PAI'] = df['Edges'].map(preferential_attachment_index(sub).get)\n",
    "    df['AAI'] = df['Edges'].map(adamic_adar_index(sub).get)\n",
    "    df['RAI'] = df['Edges'].map(resource_allocation_index(sub).get)\n",
    "    df['KzI'] = df['Edges'].map(katz_index(sub).get)\n",
    "    df['LHN2'] = df['Edges'].map(lhn2_index(sub).get)\n",
    "    df['ACT'] = df['Edges'].map(act_index(sub).get)\n",
    "    df['CBL'] = df['Edges'].map(cbl_index(sub).get)\n",
    "    df['RWR'] = df['Edges'].map(rwr_index(sub).get)\n",
    "    df['MFI'] = df['Edges'].map(matrix_forest_index(sub).get)\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def get_folds_test(G, alg = 'rf', nfolds = 10):\n",
    "    f1s = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    rocaucs = []\n",
    "    accuracies = []\n",
    "    avg_prcs = []\n",
    "    random.seed(0)\n",
    "    frames, folds = run_10_fold_on_G(G)\n",
    "    edges = []\n",
    "    for e in nx.non_edges(G):\n",
    "        edges.append(e)\n",
    "    zeros = [i for i in chunk(edges, len(edges)/len(folds[0]))]\n",
    "    zeros = zeros[:10]\n",
    "    #for j in xrange(nfolds):\n",
    "    #    test_dataset = frames[j]\n",
    "    #    train_dataset = pd.concat(frames[:j] + frames[(j+1):])\n",
    "    #    y_train = np.array(train_dataset['y'])\n",
    "    #    X_train = np.nan_to_num(\n",
    "    #        np.array(train_dataset[list(set(train_dataset.columns) - set(['y', 'Edges']))]).astype('float32'))\n",
    "    #    X_train = preprocessing.normalize(X_train, norm = 'l2')\n",
    "    #    rf = ensemble.RandomForestClassifier(class_weight = 'auto')\n",
    "    #    rf.fit(X_train, y_train)\n",
    "    #    X_test = np.nan_to_num(\n",
    "    #        np.array(test_dataset[list(set(test_dataset.columns) - set(['y', 'Edges']))]).astype('float32'))\n",
    "    #    X_test = preprocessing.normalize(X_test, norm = 'l2')\n",
    "    #    y_test = np.array(test_dataset['y'])\n",
    "    #    print 'cr on test for fold', j+1\n",
    "    #    y_pred = rf.predict(X_test)\n",
    "    #    print classification_report(y_test, y_pred)\n",
    "    #    f1s.append(metrics.f1_score(y_test, y_pred))\n",
    "    #    precisions.append(metrics.precision_score(y_test, y_pred))\n",
    "    #    recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "    #    rocaucs.append(metrics.roc_auc_score(y_test, y_pred))\n",
    "    #    accuracies.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    #    avg_prcs.append(metrics.average_precision_score(y_test, y_pred))\n",
    "    train_dataset = pd.concat([(i[i['y'] == 1]) for i in frames])\n",
    "    zero_set = pd.DataFrame()\n",
    "    for i in xrange(len(zeros)):\n",
    "        #print zeros[i]\n",
    "        #zed = []\n",
    "        #for e in zeros[i]:\n",
    "        #    zed.append(frames[i][frames[i]['Edges'] == e])\n",
    "        #z = pd.concat(zed)\n",
    "        z = frames[i][[(j in zeros[i]) for j in frames[i]['Edges']]]\n",
    "        zero_set = pd.concat([zero_set, z])\n",
    "    #print zero_set\n",
    "    #print train_dataset\n",
    "    train_dataset = pd.concat([train_dataset, zero_set])\n",
    "    y = np.array(train_dataset['y'])\n",
    "    cv = cross_validation.StratifiedKFold(y, 10)\n",
    "    X = np.nan_to_num(\n",
    "        np.array(train_dataset[list(set(train_dataset.columns) - set(['y', 'Edges']))]).astype('float32'))\n",
    "    X = preprocessing.normalize(X, norm = 'l2')\n",
    "    scores = []\n",
    "    rf = ensemble.RandomForestClassifier(class_weight = 'auto')\n",
    "    scores = cross_validation.cross_val_score(rf, X, y = y, cv = cv, n_jobs = -1)\n",
    "    print 'Random Forest:'\n",
    "    print \"Accuracy: {:.3f} (+/- {:.3f})\\n\".format(scores.mean(), scores.std() * 2)\n",
    "    rf = svm.SVC(kernel = 'poly', class_weight = 'auto')\n",
    "    scores = cross_validation.cross_val_score(rf, X, y = y, cv = cv, n_jobs = -1)\n",
    "    print 'SVM with plynomial kernel:'\n",
    "    print \"Accuracy: {:.3f} (+/- {:.3f})\\n\".format(scores.mean(), scores.std() * 2)\n",
    "    rf = svm.SVC(class_weight = 'auto')\n",
    "    scores = cross_validation.cross_val_score(rf, X, y = y, cv = cv, n_jobs = -1)\n",
    "    print 'SVM:'\n",
    "    print \"Accuracy: {:.3f} (+/- {:.3f})\\n\".format(scores.mean(), scores.std() * 2)\n",
    "    rf = neighbors.KNeighborsClassifier()\n",
    "    scores = cross_validation.cross_val_score(rf, X, y = y, cv = cv, n_jobs = -1)\n",
    "    print 'KNN:'\n",
    "    print \"Accuracy: {:.3f} (+/- {:.3f})\\n\".format(scores.mean(), scores.std() * 2)\n",
    "    rf = tree.DecisionTreeClassifier(class_weight = 'auto')\n",
    "    scores = cross_validation.cross_val_score(rf, X, y = y, cv = cv, n_jobs = -1)\n",
    "    print 'Decision tree:'\n",
    "    print \"Accuracy: {:.3f} (+/- {:.3f})\\n\".format(scores.mean(), scores.std() * 2)\n",
    "    #print 'Scores:', scores\n",
    "    #print \"Accuracy: {:.3f} (+/- {:.3f})\\n\".format(scores.mean(), scores.std() * 2)\n",
    "    #print 'mean infos:'\n",
    "    #print 'mean F1:', np.mean(f1s)\n",
    "    #print 'mean precision:', np.mean(precisions)\n",
    "    #print 'mean recall:', np.mean(recalls)\n",
    "    #print 'mean roc_auc:', np.mean(rocaucs)\n",
    "    #print 'mean accuracy:', np.mean(accuracies)\n",
    "    #print 'mean avg_precision:', np.mean(avg_prcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:139: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.703 (+/- 0.242)\n",
      "\n",
      "SVM with plynomial kernel:\n",
      "Accuracy: 0.498 (+/- 0.044)\n",
      "\n",
      "SVM:\n",
      "Accuracy: 0.498 (+/- 0.044)\n",
      "\n",
      "KNN:\n",
      "Accuracy: 0.639 (+/- 0.239)\n",
      "\n",
      "Decision tree:\n",
      "Accuracy: 0.678 (+/- 0.137)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_folds_test(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:139: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.661 (+/- 0.063)\n",
      "\n",
      "SVM with plynomial kernel:\n",
      "Accuracy: 0.503 (+/- 0.017)\n",
      "\n",
      "SVM:\n",
      "Accuracy: 0.506 (+/- 0.071)\n",
      "\n",
      "KNN:\n",
      "Accuracy: 0.675 (+/- 0.085)\n",
      "\n",
      "Decision tree:\n",
      "Accuracy: 0.636 (+/- 0.086)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newman_adjnoun = nx.read_gml('./netws/newman/adjnoun/adjnoun.gml')\n",
    "get_folds_test(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.907 (+/- 0.021)\n",
      "\n",
      "SVM with plynomial kernel:\n",
      "Accuracy: 0.500 (+/- 0.003)\n",
      "\n",
      "SVM:\n",
      "Accuracy: 0.589 (+/- 0.036)\n",
      "\n",
      "KNN:\n",
      "Accuracy: 0.892 (+/- 0.027)\n",
      "\n",
      "Decision tree:\n",
      "Accuracy: 0.880 (+/- 0.029)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pajek_us_air = nx.read_pajek('./netws/pajekds/USAir97.net')\n",
    "fixed_pajek_us_air = nx.Graph(nx.convert_node_labels_to_integers(pajek_us_air, first_label = 0))\n",
    "get_folds_test(fixed_pajek_us_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
