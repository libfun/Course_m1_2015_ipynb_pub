{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try what Dima's proposing, but with local idices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "import scipy.io as sci\n",
    "%matplotlib inline\n",
    "def chunk(xs, n):\n",
    "    ys = list(xs)\n",
    "    random.shuffle(ys)\n",
    "    size = len(ys) // n\n",
    "    leftovers= ys[size*n:]\n",
    "    for c in xrange(n):\n",
    "        if leftovers:\n",
    "           extra= [ leftovers.pop() ] \n",
    "        else:\n",
    "           extra= []\n",
    "        yield ys[c*size:(c+1)*size] + extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def common_neighbours(sub, e):\n",
    "    return float(len(sorted(nx.common_neighbors(sub, e[0], e[1]))))\n",
    "\n",
    "def salton_index(sub, e):\n",
    "    j = nx.degree(sub, e[0])\n",
    "    k = nx.degree(sub, e[1])\n",
    "    if j != 0 and k != 0:\n",
    "        return float(len(sorted(nx.common_neighbors(sub, e[0], e[1]))))/float(np.sqrt(j * k))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def jaccard_index(sub, e):\n",
    "    j = nx.degree(sub, e[0])\n",
    "    k = nx.degree(sub, e[1])\n",
    "    if j != 0 or k != 0:\n",
    "        return float(len(sorted(nx.common_neighbors(sub, e[0], e[1]))))/float(len(set(sub[e[0]])|set(sub[e[1]])))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def sorensen_index(sub, e):\n",
    "    j = nx.degree(sub, e[0])\n",
    "    k = nx.degree(sub, e[1])\n",
    "    if j != 0 or k != 0:\n",
    "        return float(len(sorted(nx.common_neighbors(sub, e[0], e[1]))))/float(j + k)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def hub_promoted_index(sub, e):\n",
    "    j = nx.degree(sub, e[0])\n",
    "    k = nx.degree(sub, e[1])\n",
    "    if j != 0 and k != 0:\n",
    "        return float(len(sorted(nx.common_neighbors(sub, e[0], e[1]))))/float(min(j, k))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def hub_depressed_index(sub, e):\n",
    "    j = nx.degree(sub, e[0])\n",
    "    k = nx.degree(sub, e[1])\n",
    "    if j != 0 or k != 0:\n",
    "        return float(len(sorted(nx.common_neighbors(sub, e[0], e[1]))))/float(max(j, k))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def LHN1_index(sub, e):\n",
    "    j = nx.degree(sub, e[0])\n",
    "    k = nx.degree(sub, e[1])\n",
    "    if j != 0 and k != 0:\n",
    "        return float(len(sorted(nx.common_neighbors(sub, e[0], e[1]))))/float(j * k)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def preferential_attachment_index(sub, e):\n",
    "    return nx.degree(sub, e[0]) * nx.degree(sub, e[1])\n",
    "\n",
    "def adamic_adar_index(sub, e):\n",
    "    return np.sum(1/np.log(nx.degree(sub, sorted(nx.common_neighbors(sub, e[0], e[1]))).values()))\n",
    "\n",
    "def resource_allocation_index(sub, e):\n",
    "    return np.sum(1/np.array(\n",
    "                nx.degree(sub, sorted(nx.common_neighbors(sub, e[0], e[1]))).values()).astype(float))\n",
    "\n",
    "def predict_nodes(G, nfolds = 10):\n",
    "    df = pd.DataFrame()\n",
    "    es = nx.non_edges(G)\n",
    "    cn = {}\n",
    "    sai = {}\n",
    "    ji = {}\n",
    "    soi = {}\n",
    "    hpi = {}\n",
    "    hdi = {}\n",
    "    lhn1 = {}\n",
    "    pai = {}\n",
    "    aai = {}\n",
    "    rai = {}\n",
    "    edges = []\n",
    "    y = {}\n",
    "    for e in es:\n",
    "        edges.append(e)\n",
    "        y[e] = 0\n",
    "        cn[e] = common_neighbours(G, e)\n",
    "        sai[e] = salton_index(G, e)\n",
    "        ji[e] = jaccard_index(G, e)\n",
    "        soi[e] = sorensen_index(G, e)\n",
    "        hpi[e] = hub_promoted_index(G, e)\n",
    "        hdi[e] = hub_depressed_index(G, e)\n",
    "        lhn1[e] = LHN1_index(G, e)\n",
    "        pai[e] = preferential_attachment_index(G, e)\n",
    "        aai[e] = adamic_adar_index(G, e)\n",
    "        rai[e] = resource_allocation_index(G, e)\n",
    "    eds = G.edges()\n",
    "    for e in eds:\n",
    "        s = G.copy()\n",
    "        s.remove_edge(*e)\n",
    "        edges.append(e)\n",
    "        y[e] = 1\n",
    "        cn[e] = common_neighbours(s, e)\n",
    "        sai[e] = salton_index(s, e)\n",
    "        ji[e] = jaccard_index(s, e)\n",
    "        soi[e] = sorensen_index(s, e)\n",
    "        hpi[e] = hub_promoted_index(s, e)\n",
    "        hdi[e] = hub_depressed_index(s, e)\n",
    "        lhn1[e] = LHN1_index(s, e)\n",
    "        pai[e] = preferential_attachment_index(s, e)\n",
    "        aai[e] = adamic_adar_index(s, e)\n",
    "        rai[e] = resource_allocation_index(s, e)\n",
    "        s = 0\n",
    "    df['Edges'] = edges\n",
    "    df['y'] = df['Edges'].map(y.get)\n",
    "    df['CN'] = df['Edges'].map(cn.get)\n",
    "    df['SaI'] = df['Edges'].map(sai.get)\n",
    "    df['JI'] = df['Edges'].map(ji.get)\n",
    "    df['SoI'] = df['Edges'].map(soi.get)\n",
    "    df['HPI'] = df['Edges'].map(hpi.get)\n",
    "    df['HDI'] = df['Edges'].map(hdi.get)\n",
    "    df['LHN1'] = df['Edges'].map(lhn1.get)\n",
    "    df['PAI'] = df['Edges'].map(pai.get)\n",
    "    df['AAI'] = df['Edges'].map(aai.get)\n",
    "    df['RAI'] = df['Edges'].map(rai.get)\n",
    "    df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn import lda\n",
    "from sklearn import qda\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_indices_on_compl(sub, fold):\n",
    "    df = pd.DataFrame()\n",
    "    es = nx.non_edges(sub)\n",
    "    cn = {}\n",
    "    sai = {}\n",
    "    ji = {}\n",
    "    soi = {}\n",
    "    hpi = {}\n",
    "    hdi = {}\n",
    "    lhn1 = {}\n",
    "    pai = {}\n",
    "    aai = {}\n",
    "    rai = {}\n",
    "    edges = []\n",
    "    y = {}\n",
    "    for e in es:\n",
    "        edges.append(e)\n",
    "        if e in fold:\n",
    "            y[e] = 1\n",
    "        else:\n",
    "            y[e] = 0\n",
    "        cn[e] = common_neighbours(sub, e)\n",
    "        sai[e] = salton_index(sub, e)\n",
    "        ji[e] = jaccard_index(sub, e)\n",
    "        soi[e] = sorensen_index(sub, e)\n",
    "        hpi[e] = hub_promoted_index(sub, e)\n",
    "        hdi[e] = hub_depressed_index(sub, e)\n",
    "        lhn1[e] = LHN1_index(sub, e)\n",
    "        pai[e] = preferential_attachment_index(sub, e)\n",
    "        aai[e] = adamic_adar_index(sub, e)\n",
    "        rai[e] = resource_allocation_index(sub, e)\n",
    "    df['Edges'] = edges\n",
    "    df['y'] = df['Edges'].map(y.get)\n",
    "    df['CN'] = df['Edges'].map(cn.get)\n",
    "    df['SaI'] = df['Edges'].map(sai.get)\n",
    "    df['JI'] = df['Edges'].map(ji.get)\n",
    "    df['SoI'] = df['Edges'].map(soi.get)\n",
    "    df['HPI'] = df['Edges'].map(hpi.get)\n",
    "    df['HDI'] = df['Edges'].map(hdi.get)\n",
    "    df['LHN1'] = df['Edges'].map(lhn1.get)\n",
    "    df['PAI'] = df['Edges'].map(pai.get)\n",
    "    df['AAI'] = df['Edges'].map(aai.get)\n",
    "    df['RAI'] = df['Edges'].map(rai.get)\n",
    "    df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def run_folds_alg(G, nfolds = 10):\n",
    "    f1s = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    rocaucs = []\n",
    "    accuracies = []\n",
    "    avg_prcs = []\n",
    "    random.seed(0)\n",
    "    fs = [i for i in chunk(G.edges(), nfolds)]\n",
    "    for i in xrange(nfolds):\n",
    "        sub = G.copy()\n",
    "        for e in fs[i]:\n",
    "            sub.remove_edge(*e)\n",
    "        train_dataset = predict_nodes(sub)\n",
    "        y = np.array(train_dataset['y'])\n",
    "        cv = cross_validation.StratifiedKFold(y, 10)\n",
    "        X = np.nan_to_num(\n",
    "            np.array(train_dataset[list(set(train_dataset.columns) - set(['y', 'Edges']))]).astype('float32'))\n",
    "        rf = ensemble.RandomForestClassifier(class_weight = 'auto')\n",
    "        rf.fit(X, y)\n",
    "        df = run_indices_on_compl(sub, fs[i])\n",
    "        X_test = np.nan_to_num(np.array(df[list(set(df.columns) - set(['y', 'Edges']))]).astype('float32'))\n",
    "        y_test = np.array(df['y'])\n",
    "        y_pred = rf.predict(X_test)\n",
    "        #print y_test\n",
    "        #print y_pred\n",
    "        f1s.append(metrics.f1_score(y_test, y_pred))\n",
    "        precisions.append(metrics.precision_score(y_test, y_pred))\n",
    "        recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        rocaucs.append(metrics.roc_auc_score(y_test, y_pred))\n",
    "        accuracies.append(metrics.accuracy_score(y_test, y_pred))\n",
    "        avg_prcs.append(metrics.average_precision_score(y_test, y_pred))\n",
    "        #print 'Accuracy:', metrics.accuracy_score(y_test, rf.predict(X_test))\n",
    "        #scores = cross_validation.cross_val_score(rf, X, y = y, cv = cv, n_jobs = -1)\n",
    "    print 'infos:'\n",
    "    print 'F1: {:.3f} (+/- {:.3f})'.format(np.mean(f1s), np.std(f1s))\n",
    "    print 'Precision: {:.3f} (+/- {:.3f})'.format(np.mean(precisions), np.std(precisions))\n",
    "    print 'Recall: {:.3f} (+/- {:.3f})'.format(np.mean(recalls), np.std(recalls))\n",
    "    print 'ROC_AUC: {:.3f} (+/- {:.3f})'.format(np.mean(rocaucs), np.std(rocaucs))\n",
    "    print 'Accuracy: {:.3f} (+/- {:.3f})'.format(np.mean(accuracies), np.std(accuracies))\n",
    "    print 'Avg_precision: {:.3f} (+/- {:.3f})'.format(np.mean(avg_prcs), np.std(avg_prcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infos:\n",
      "F1: 0.028 (+/- 0.048)\n",
      "Precision: 0.020 (+/- 0.034)\n",
      "Recall: 0.050 (+/- 0.083)\n",
      "ROC_AUC: 0.506 (+/- 0.042)\n",
      "Accuracy: 0.947 (+/- 0.023)\n",
      "Avg_precision: 0.042 (+/- 0.057)\n"
     ]
    }
   ],
   "source": [
    "run_folds_alg(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infos:\n",
      "F1: 0.018 (+/- 0.009)\n",
      "Precision: 0.010 (+/- 0.005)\n",
      "Recall: 0.089 (+/- 0.045)\n",
      "ROC_AUC: 0.512 (+/- 0.022)\n",
      "Accuracy: 0.928 (+/- 0.012)\n",
      "Avg_precision: 0.053 (+/- 0.025)\n"
     ]
    }
   ],
   "source": [
    "newman_adjnoun = nx.read_gml('./netws/newman/adjnoun/adjnoun.gml')\n",
    "run_folds_alg(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infos:\n",
      "F1: 0.028 (+/- 0.015)\n",
      "Precision: 0.035 (+/- 0.028)\n",
      "Recall: 0.032 (+/- 0.009)\n",
      "ROC_AUC: 0.511 (+/- 0.005)\n",
      "Accuracy: 0.987 (+/- 0.011)\n",
      "Avg_precision: 0.036 (+/- 0.015)\n"
     ]
    }
   ],
   "source": [
    "pajek_us_air = nx.read_pajek('./netws/pajekds/USAir97.net')\n",
    "fixed_pajek_us_air = nx.Graph(nx.convert_node_labels_to_integers(pajek_us_air, first_label = 0))\n",
    "run_folds_alg(fixed_pajek_us_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
