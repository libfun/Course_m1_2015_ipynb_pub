{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Notebook for link prediciton analysis\n",
    "##Coursework 2015, HSE - DataSci\n",
    "###Sergey Korolev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####First attempt, similarity based algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Networks used:\n",
    "1. UciNet data - http://vlado.fmf.uni-lj.si/pub/networks/data/UciNet/UciData.htm\n",
    "2. Pajek datasets - http://vlado.fmf.uni-lj.si/pub/networks/data/default.htm\n",
    "3. ND - http://www3.nd.edu/~networks/resources.htm (possibly already in pajek ds)\n",
    "4. Alex Arenas - http://deim.urv.cat/~alexandre.arenas/data/welcome.htm\n",
    "5. Stanford nets - http://snap.stanford.edu/data/\n",
    "6. Newman - http://www-personal.umich.edu/~mejn/netdata/\n",
    "\n",
    "Really hope to sift through them or just write some interface to load them into networkx to work with them.\n",
    "\n",
    "#####All theoretical notes on the algroithms are quoted directly from Linyuan LuÌˆ, Tao Zhou, Link prediction in complex networks: A survey, Physica A 390, 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "import scipy.io as sci\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunk(xs, n):\n",
    "    ys = list(xs)\n",
    "    random.shuffle(ys)\n",
    "    size = len(ys) // n\n",
    "    leftovers= ys[size*n:]\n",
    "    for c in xrange(n):\n",
    "        if leftovers:\n",
    "           extra= [ leftovers.pop() ] \n",
    "        else:\n",
    "           extra= []\n",
    "        yield ys[c*size:(c+1)*size] + extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Common neighbours\n",
    "For a node x, let $\\Gamma(x)$ denote the set of neighbors of $x$. In common sense, two nodes, $x$ and $y$, are more likely to have a link if they have many common neighbors. The simplest measure of this neighborhood overlap is the directed count, namely\n",
    "$$s_{xy}^{CN} = |\\Gamma(x) \\cap \\Gamma(y)|,$$\n",
    "where $|Q|$ is the cardinality of the set $Q$. It is obvious that $s_{xy} = (A^2)_{xy}$, where $A$ is the adjacency matrix: $A_{xy} = 1$ if $x$ and $y$ are directly connected and $A_{xy} = 0$ otherwise. Note that, $(A^2)_{xy}$ is also the number of different paths with length 2 connecting $x$ and $y$. Newman [40] used this quantity in the study of collaboration networks, showing a positive correlation between the number of common neighbors and the probability that two scientists will collaborate in the future. Kossinets and Watts [14] analyzed a large-scale social network, suggesting that two students having many mutual friends are very probable to be friends in future. The following six indices are also based on the number of common neighbors, yet with different normalization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folds = [i for i in chunk(G.edges(), 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subs = []\n",
    "for i in xrange(10):\n",
    "    graph = G.copy()\n",
    "    for c in folds[i]:\n",
    "        graph.remove_edge(*c)\n",
    "    subs.append(graph.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def common_neighbours(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = mat[e[0]][e[1]]\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Salton Index\n",
    "It is defined as\n",
    "$$s_{xy}^{Salton} = \\frac{|\\Gamma(x) \\cap \\Gamma(y)|}{\\sqrt{k_x \\times k_x}}$$\n",
    "where $k_x$ is the degree of node $x$. The Salton index is also called the cosine similarity in the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def salton_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            j = nx.degree(i, e[0])\n",
    "            k = nx.degree(i, e[1])\n",
    "            if j != 0 and k != 0:\n",
    "                edgesWithScore[e] = float(mat[e[0]][e[1]])/float(np.sqrt(j * k))\n",
    "            else:\n",
    "                edgesWithScore[e] = 0\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####Jaccard Index\n",
    "This index was proposed by Jaccard over a hundred years ago, and is defined as\n",
    "$$s_{xy}^{Jaccard} = \\frac{|\\Gamma(x) \\cap \\Gamma(y)|}{|\\Gamma(x) \\cup \\Gamma(y)|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            if nx.degree(i, e[0]) != 0 or nx.degree(i, e[1]) != 0:\n",
    "                edgesWithScore[e] = float(mat[e[0]][e[1]])/float(len(set(i[e[0]])|set(i[e[1]])))\n",
    "            else:\n",
    "                edgesWithScore[e] = 0\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Sorensen Index\n",
    "This index is used mainly for ecological community data, and is defined as\n",
    "$$s_{xy}^{Sorensen} = \\frac{2|\\Gamma(x) \\cap \\Gamma(y)|}{k_x + k_y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sorensen_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            j = nx.degree(i, e[0])\n",
    "            k = nx.degree(i, e[1])\n",
    "            if j != 0 or k != 0:\n",
    "                edgesWithScore[e] = 2*float(mat[e[0]][e[1]])/float(j + k)\n",
    "            else:\n",
    "                edgesWithScore[e] = 0\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Hub Promoted Index (HPI)\n",
    "This index is proposed for quantifying the topological overlap of pairs of substrates in metabolic networks, and is defined as\n",
    "$$s_{xy}^{HPI} = \\frac{|\\Gamma(x) \\cap \\Gamma(y)|}{min\\{k_x, k_y\\}}$$\n",
    "Under this measurement, the links adjacent to hubs are likely to be assigned high scores since the denominator is determined by the lower degree only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hub_promoted_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            j = nx.degree(i, e[0])\n",
    "            k = nx.degree(i, e[1])\n",
    "            if j != 0 and k != 0:\n",
    "                edgesWithScore[e] = float(mat[e[0]][e[1]])/float(min(j, k))\n",
    "            else:\n",
    "                edgesWithScore[e] = 0\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Hub Depressed Index (HDI)\n",
    "Analogously to the above index, we also consider a measurement with the opposite effect on hubs, defined as\n",
    "$$s_{xy}^{HDI} = \\frac{|\\Gamma(x) \\cap \\Gamma(y)|}{max\\{k_x, k_y\\}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hub_depressed_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            j = nx.degree(i, e[0])\n",
    "            k = nx.degree(i, e[1])\n",
    "            if j != 0 or k != 0:\n",
    "                edgesWithScore[e] = float(mat[e[0]][e[1]])/float(max(j, k))\n",
    "            else:\n",
    "                edgesWithScore[e] = 0\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Leichtâ€“Holmeâ€“Newman Index (LHN1)\n",
    "This index assigns high similarity to node pairs that have many common neighbors compared not to the possible maximum, but to the expected number of such neighbors. It is defined as\n",
    "$$s_{xy}^{LHN1} = \\frac{|\\Gamma(x) \\cap \\Gamma(y)|}{k_x \\times k_y}$$\n",
    "where the denominator, $k_x \\times k_y$, is proportional to the expected number of common neighbors of nodes $x$ and $y$ in the configuration model. We use the abbreviation LHN1 to distinguish this index to another index (named as LHN2 index) also proposed by Leicht, Holme and Newman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LHN1_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            j = nx.degree(i, e[0])\n",
    "            k = nx.degree(i, e[1])\n",
    "            if j != 0 and k != 0:\n",
    "                edgesWithScore[e] = float(mat[e[0]][e[1]])/float(j * k)\n",
    "            else:\n",
    "                edgesWithScore[e] = 0\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Preferential Attachment Index (PA)\n",
    "The mechanism of preferential attachment can be used to generate evolving scale- free networks, where the probability that a new link is connected to the node $x$ is proportional to $k_x$. A similar mechanism can also lead to scale-free networks without growth, where at each time step, an old link is removed and a new link is generated. The probability that this new link will connect $x$ and $y$ is proportional to $k_x \\times k_y$. Motivated by this mechanism, the corresponding similarity index can be defined as\n",
    "$$s_{xy}^{PA} = k_x \\times k_y$$\n",
    "which has been widely used to quantify the functional significance of links subject to various network-based dynamics, such as percolation, synchronization and transportation. Note that, this index does not require the information of the neighborhood of each node, as a consequence, it has the least computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preferential_attachment_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = nx.degree(i, e[0]) * nx.degree(i, e[1])\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Adamicâ€“Adar Index (AA)\n",
    "This index refines the simple counting of common neighbors by assigning the less- connected neighbors more weights, and is defined as\n",
    "$$s_{xy}^{AA} = \\sum_{z \\in \\Gamma(x) \\cap \\Gamma(y)} \\frac{1}{log k_z}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adamic_adar_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = np.sum(1/np.log(nx.degree(i, sorted(nx.common_neighbors(i, e[0], e[1]))).values()))\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "        \n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Resource Allocation Index (RA)\n",
    "This index is motivated by the resource allocation dynamics on complex networks. Consider a pair of nodes, $x$ and $y$, which are not directly connected. The node $x$ can send some resource to $y$, with their common neighbors playing the role of transmitters. In the simplest case, we assume that each transmitter has a unit of resource, and will equally distribute it to all its neighbors. The similarity between $x$ and $y$ can be defined as the amount of resource $y$ received from $x$, which is\n",
    "$$s_{xy}^{RA} = \\sum_{z \\in \\Gamma(x) \\cap \\Gamma(y)} \\frac{1}{k_z}$$\n",
    "Clearly,this measure is symmetric,namely $s_{xy} = s_{yx}$.Note that, although resulting from different motivations, the AA index and RA index have very similar form. Indeed, they both depress the contribution of the high-degree common neighbors. AA index takes the form $(log k )^{âˆ’1}$ while RA index takes the form $k^{âˆ’1}$. The difference is insignificant when the degree, $k_z$, is small, while it is considerable when $k_z$ is large. In other words, RA index punishes the high-degree common neighbors more heavily than AA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resourse_allocation_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = np.sum(1/np.array(\n",
    "                    nx.degree(i, sorted(nx.common_neighbors(i, e[0], e[1]))).values()).astype(float))\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "        \n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_local_similarity_indices(G, symmetric = True, nfolds = 10, seed = 0):\n",
    "    random.seed(seed)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    cn = common_neighbours(folds, subs, symmetric = symmetric)\n",
    "    print 'cn'\n",
    "    sai = salton_index(folds, subs, symmetric = symmetric)\n",
    "    print 'sai'\n",
    "    ji = jaccard_index(folds, subs, symmetric = symmetric)\n",
    "    print 'ji'\n",
    "    soi = sorensen_index(folds, subs, symmetric = symmetric)\n",
    "    print 'soi'\n",
    "    hpi = hub_promoted_index(folds, subs, symmetric = symmetric)\n",
    "    print 'hpi'\n",
    "    hdi = hub_depressed_index(folds, subs, symmetric = symmetric)\n",
    "    print 'hdi'\n",
    "    lhn1 = LHN1_index(folds, subs, symmetric = symmetric)\n",
    "    print 'LHN1'\n",
    "    pai = preferential_attachment_index(folds, subs, symmetric = symmetric)\n",
    "    print 'pai'\n",
    "    aai = adamic_adar_index(folds, subs, symmetric = symmetric)\n",
    "    print 'aai'\n",
    "    rai = resourse_allocation_index(folds, subs, symmetric = symmetric)\n",
    "    print 'rai'\n",
    "    aucs = {'CN' : cn, \n",
    "            'SaI' : sai, \n",
    "            'JI' : ji, \n",
    "            'SoI' : soi,\n",
    "            'HPI' : hpi,\n",
    "            'HDI' : hdi,\n",
    "            'LHN1' : lhn1,\n",
    "            'PAI' : pai,\n",
    "            'AAI' : aai,\n",
    "            'RAI' : rai}\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['CN', 'SaI', 'JI', 'SoI', 'HPI', 'HDI', 'LHN1', 'PAI', 'AAI', 'RAI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc['karate club'] = run_local_similarity_indices(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pajek_football = nx.read_pajek('./netws/pajekds/football.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixed_pajek_football = nx.Graph(nx.convert_node_labels_to_integers(pajek_football, first_label = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc['pajek football'] = run_local_similarity_indices(fixed_pajek_football)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pajek_us_air = nx.read_pajek('./netws/pajekds/USAir97.net')\n",
    "fixed_pajek_us_air = nx.Graph(nx.convert_node_labels_to_integers(pajek_us_air, first_label = 0))\n",
    "pajek_us_air = 0\n",
    "df.loc['pajek_us_air'] = run_local_similarity_indices(fixed_pajek_us_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pajek_netscience = nx.read_pajek('./netws/pajekds/netsience.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixed_pajek_netscience = nx.Graph(nx.convert_node_labels_to_integers(pajek_netscience, first_label = 0))\n",
    "pajek_netscience = 0\n",
    "df.loc['pajek netscience'] = run_local_similarity_indices(fixed_pajek_netscience)\n",
    "fixed_pajek_netscience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CN</th>\n",
       "      <th>SaI</th>\n",
       "      <th>JI</th>\n",
       "      <th>SoI</th>\n",
       "      <th>HPI</th>\n",
       "      <th>HDI</th>\n",
       "      <th>LHN1</th>\n",
       "      <th>PAI</th>\n",
       "      <th>AAI</th>\n",
       "      <th>RAI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>karate club</th>\n",
       "      <td> 0.699908</td>\n",
       "      <td> 0.636143</td>\n",
       "      <td> 0.606829</td>\n",
       "      <td> 0.606829</td>\n",
       "      <td> 0.712276</td>\n",
       "      <td> 0.592641</td>\n",
       "      <td> 0.599922</td>\n",
       "      <td> 0.711626</td>\n",
       "      <td> 0.725595</td>\n",
       "      <td> 0.733396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pajek football</th>\n",
       "      <td> 0.662064</td>\n",
       "      <td> 0.588845</td>\n",
       "      <td> 0.587198</td>\n",
       "      <td> 0.587198</td>\n",
       "      <td> 0.600118</td>\n",
       "      <td> 0.578401</td>\n",
       "      <td> 0.490883</td>\n",
       "      <td> 0.754943</td>\n",
       "      <td> 0.658615</td>\n",
       "      <td> 0.652655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pajek_us_air</th>\n",
       "      <td> 0.934896</td>\n",
       "      <td> 0.908560</td>\n",
       "      <td> 0.898030</td>\n",
       "      <td> 0.898030</td>\n",
       "      <td> 0.870076</td>\n",
       "      <td> 0.891644</td>\n",
       "      <td> 0.767659</td>\n",
       "      <td> 0.886947</td>\n",
       "      <td> 0.945853</td>\n",
       "      <td> 0.951752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pajek netscience</th>\n",
       "      <td> 0.940165</td>\n",
       "      <td> 0.940314</td>\n",
       "      <td> 0.940269</td>\n",
       "      <td> 0.940269</td>\n",
       "      <td> 0.940200</td>\n",
       "      <td> 0.940221</td>\n",
       "      <td> 0.939941</td>\n",
       "      <td> 0.679141</td>\n",
       "      <td> 0.940459</td>\n",
       "      <td> 0.940473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        CN       SaI        JI       SoI       HPI       HDI  \\\n",
       "karate club       0.699908  0.636143  0.606829  0.606829  0.712276  0.592641   \n",
       "pajek football    0.662064  0.588845  0.587198  0.587198  0.600118  0.578401   \n",
       "pajek_us_air      0.934896  0.908560  0.898030  0.898030  0.870076  0.891644   \n",
       "pajek netscience  0.940165  0.940314  0.940269  0.940269  0.940200  0.940221   \n",
       "\n",
       "                      LHN1       PAI       AAI       RAI  \n",
       "karate club       0.599922  0.711626  0.725595  0.733396  \n",
       "pajek football    0.490883  0.754943  0.658615  0.652655  \n",
       "pajek_us_air      0.767659  0.886947  0.945853  0.951752  \n",
       "pajek netscience  0.939941  0.679141  0.940459  0.940473  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('first_four.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Global similarity indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####1. Katz Index\n",
    "This index is based on the ensemble of all paths, which directly sums over the collection of paths\n",
    "and is exponentially damped by length to give the shorter paths more weights. The mathematical expression reads\n",
    "$$S^{Katz} = (I - \\beta A)^{-1} - I.$$\n",
    "Note that, Î² must be lower than the reciprocal of the largest eigenvalue of matrix A to ensure the convergence of Eq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def katz_index(folds, subs, beta = 0, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "        ide = np.identity(len(mat))\n",
    "        if beta == 0:\n",
    "            beta = (1/float(max(np.linalg.eig(mat)[0])))/2\n",
    "            print 'beta =', beta\n",
    "        sim = np.linalg.inv(ide - beta*mat) - ide\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####2. Leichtâ€“Holmeâ€“Newman Index (LHN2)\n",
    "This index is a variant of the Katz index. Based on the concept that two\n",
    "nodes are similar if their immediate neighbors are themselves similar, one obtains a self-consistent matrix formulation\n",
    "$$S^{LHN2} = 2 m \\lambda_1 D^{-1} (I - \\frac{\\phi A}{\\lambda_1})^{-1} D^{-1},$$\n",
    "where $\\lambda_1$ is the largest eigenvalue of $A$, $m$ is the total number of edges in the network and $D$ is the degree matrix with $D_{xy} = \\delta_{xy}k_x$ and $\\phi (0 < \\phi < 1)$ is a free parameter. The choosing of $\\phi$ depends on the investigated network, and smaller $\\phi$ assigns more weights on shorter paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lhn2_index(folds, subs, phi = 0.5, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "        ide = np.identity(len(mat))\n",
    "        dma = np.diagflat(mat.sum(axis = 1))\n",
    "        if np.linalg.det(dma) != 0:\n",
    "            lambd = float(max(np.linalg.eig(mat)[0]))\n",
    "            sim = (2 * i.number_of_edges() * lambd * np.linalg.inv(dma)).dot(np.linalg.inv(\n",
    "            ide - (phi/lambd) * mat)).dot(np.linalg.inv(dma))\n",
    "            edgesWithScore = {}\n",
    "            edges = nx.non_edges(i)\n",
    "            for e in edges:\n",
    "                edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "            highScore = 0\n",
    "            sameScore = 0\n",
    "            allScore = 0\n",
    "            for e in edgesWithScore:\n",
    "                if e not in folds[step]:\n",
    "                    for s in folds[step]:\n",
    "                        if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                            highScore += 1\n",
    "                        elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                            sameScore += 1\n",
    "                        allScore += 1\n",
    "            auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####3. Average Commute Time (ACT)\n",
    "Assuming two nodes are more similar if they have a smaller average commute time, then the similarity between the nodes x and y can be defined as the reciprocal of $n(x, y)$, namely (the constant factor M is removed)\n",
    "$$S_{xy}^{ACT} = \\frac{1}{l_{xx}^{+} + l_{yy}^{+} - 2l_{xy}^{+}},$$\n",
    "where $l_{xy}^{+}$ denotes the corresponding entry in the Laplacian matrix, $L^{+} (L = D âˆ’ A)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def act_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "        dma = np.diagflat(mat.sum(axis = 1))\n",
    "        sim = np.linalg.pinv(dma - mat)\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = 1/float(sim[e[0]][e[0]] + sim[e[1]][e[1]] - 2*sim[e[0]][e[1]])\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####4. Cosine based on $L^{+}$\n",
    "This index is an inner-product-based measure. In the Euclidean space spanned by $v_x = \\Lambda^{\\frac{1}{2}} U^{T} e_x,$ where $U$ is an orthonormal matrix made of the eigenvectors of $L^{+}$ ordered in decreasing order of corresponding eigenvalue $\\lambda_x, \\Lambda = diag(\\lambda_x), e_x$ is an $N \\times 1$ vector with the $x$th element equal to $1$ and others all equal to $0$, and $T$ is the matrix transposition, the pseudoinverse of the Laplacian matrix are the inner products of the node vectors, $l_{xy}^{+} = v_x^T v_y$. Accordingly, the cosine similarity is defined as the cosine of the node vectors, namely\n",
    "$$s_{xy}^{cos^{+}} = cos(x, y)^{+} = \\frac{v_x^T v_y}{|v_x| \\cdot |v_y|} = \\frac{l_{xy}^{+}}{\\sqrt{l_{xx}^{+} \\cdot l_{yy}^{+}}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cbl_index(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "        dma = np.diagflat(mat.sum(axis = 1))\n",
    "        sim = np.linalg.pinv(dma - mat)\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = float(sim[e[0]][e[1]])/np.sqrt(sim[e[0]][e[0]] * sim[e[1]][e[1]])\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####5. Random Walk with Restart (RWR)\n",
    "This index is a direct application of the PageRank algorithm. Consider a random walker starting from node $x$, who will iteratively move to a random neighbor with probability $c$ and return to node $x$ with probability $1 âˆ’ c$. Denote by $q_{xy}$ the probability this random walker locates at node $y$ in the steady state, we have\n",
    "$$q_{x} = c P^T q_x + (1 - c) e_x,$$\n",
    "where $P$ is the transition matrix with $P_{xy} = 1/k_x$ if $x$ and $y$ are connected, and $P_{xy} = 0$ otherwise. The solution is straightforward, as\n",
    "$$q_x = (1 - c) (I - cP^T)^{-1} e_x.$$\n",
    "The RWR index is thus defined as\n",
    "$$s_{xy}^{RWR} = q_{xy} + q_{yx},$$\n",
    "where $q_{xy}$ is the $y$th element of the vector $q_x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rwr_index(folds, subs, c = 0.5, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "        dma = np.diagflat(mat.sum(axis = 1))\n",
    "        sim = np.linalg.pinv(dma - mat)\n",
    "        ide = np.identity(len(mat))\n",
    "        pmt = np.identity(len(mat))\n",
    "        es = []\n",
    "        for a in i.nodes():\n",
    "            e = np.zeros(len(mat))\n",
    "            e[a] = 1\n",
    "            es.append(e)\n",
    "            for b in i.nodes():\n",
    "                try:\n",
    "                    nx.shortest_path_length(i, source = a, target = b)\n",
    "                except:\n",
    "                    pmt[a][b] = 0\n",
    "                else:\n",
    "                    if nx.degree(i, a) != 0:\n",
    "                        pmt[a][b] = 1/float(nx.degree(i, a))\n",
    "                    else:\n",
    "                        pmt[a][b] = 0\n",
    "        es = np.array(es)\n",
    "        qs = []\n",
    "        for a in i.nodes():\n",
    "            if np.linalg.det(ide - c*np.transpose(pmt)) != 0:\n",
    "                q = ((1 - c)*np.linalg.inv(ide - c*np.transpose(pmt))).dot(es[a])\n",
    "            else:\n",
    "                q = es[a]\n",
    "            qs.append(q)\n",
    "        qs = np.array(qs)\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = qs[e[0]][e[1]] + qs[e[1]][e[0]]\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####6. SimRank\n",
    "Similar to the LHN2, SimRank is defined in a self-consistent way, according to the assumption that\n",
    "two nodes are similar if they are connected to similar nodes.\n",
    "$$s_{xy}^{SimRank} = C \\cdot \\frac{\\sum_{z \\in \\Gamma(x)} \\sum_{z' \\in \\Gamma(y)} s_{zz'}^{SimRank}}{k_x \\cdot k_y},$$\n",
    "where $s_{xx} = 1$ and $C \\in [0, 1]$ is the decay factor. The SimRank can also be interpreted by the random walk process, that is, $s_{xy}^{SimRank}$ measures how soon two random walkers, respectively starting from nodes $x$ and $y$, are expected to meet at a certain node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####7. Matrix Forest Index (MFI)\n",
    "This index is defined as\n",
    "$$S = (I + L)^{-1},$$\n",
    "where the similarity between $x$ and $y$ can be understood as the ratio of the number of spanning rooted forests such that nodes $x$ and $y$ belong to the same tree rooted at $x$ to all spanning rooted forests of the network. A parameter-dependent variant of MFI is\n",
    "$$S = (I + \\alpha L)^{-1}, \\ \\ \\ \\alpha > 0.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_forest_index(folds, subs, alpha = 1, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "        dma = np.diagflat(mat.sum(axis = 1))\n",
    "        ide = np.identity(len(mat))\n",
    "        sim = np.linalg.inv(ide + alpha*(dma - mat))\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_global_similarity_indices(G, symmetric = True, nfolds = 10, seed = 0):\n",
    "    random.seed(seed)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    ki = katz_index(folds, subs, symmetric = symmetric)\n",
    "    print 'ki'\n",
    "    lhn2 = lhn2_index(folds, subs, symmetric = symmetric)\n",
    "    print 'lhn2'\n",
    "    act = act_index(folds, subs, symmetric = symmetric)\n",
    "    print 'act'\n",
    "    cbl = cbl_index(folds, subs, symmetric = symmetric)\n",
    "    print 'cbl'\n",
    "    rwr = rwr_index(folds, subs, symmetric = symmetric)\n",
    "    print 'rwr'\n",
    "    mfi = matrix_forest_index(folds, subs, symmetric = symmetric)\n",
    "    print 'mfi'\n",
    "    aucs = {'KI' : ki, \n",
    "            'LHN2' : lhn2, \n",
    "            'ACT' : act, \n",
    "            'CBL' : cbl,\n",
    "            'RWR' : rwr,\n",
    "            'MFI' : mfi}\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns = ['KI', 'LHN2', 'ACT', 'CBL', 'RWR', 'MFI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.loc['karate club'] = run_global_similarity_indices(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pajek_football = nx.read_pajek('./netws/pajekds/football.net')\n",
    "fixed_pajek_football = nx.Graph(nx.convert_node_labels_to_integers(pajek_football, first_label = 0))\n",
    "df2.loc['pajek football'] = run_global_similarity_indices(fixed_pajek_football)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pajek_us_air = nx.read_pajek('./netws/pajekds/USAir97.net')\n",
    "fixed_pajek_us_air = nx.Graph(nx.convert_node_labels_to_integers(pajek_us_air, first_label = 0))\n",
    "df2.loc['pajek_us_air'] = run_global_similarity_indices(fixed_pajek_us_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KI</th>\n",
       "      <th>LHN2</th>\n",
       "      <th>ACT</th>\n",
       "      <th>CBL</th>\n",
       "      <th>RWR</th>\n",
       "      <th>MFI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>karate club</th>\n",
       "      <td> 0.755219</td>\n",
       "      <td> 0.610452</td>\n",
       "      <td> 0.666190</td>\n",
       "      <td> 0.735803</td>\n",
       "      <td> 0.619955</td>\n",
       "      <td> 0.748715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pajek football</th>\n",
       "      <td> 0.724598</td>\n",
       "      <td> 0.521484</td>\n",
       "      <td> 0.747681</td>\n",
       "      <td> 0.596968</td>\n",
       "      <td> 0.746666</td>\n",
       "      <td> 0.679982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pajek_us_air</th>\n",
       "      <td> 0.919737</td>\n",
       "      <td>      NaN</td>\n",
       "      <td> 0.891851</td>\n",
       "      <td> 0.904232</td>\n",
       "      <td> 0.832092</td>\n",
       "      <td> 0.912749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      KI      LHN2       ACT       CBL       RWR       MFI\n",
       "karate club     0.755219  0.610452  0.666190  0.735803  0.619955  0.748715\n",
       "pajek football  0.724598  0.521484  0.747681  0.596968  0.746666  0.679982\n",
       "pajek_us_air    0.919737       NaN  0.891851  0.904232  0.832092  0.912749"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv('first_three_global.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Quasi-local indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####1.Local Path Index (LP)\n",
    "To provide a good tradeoff of accuracy and computational complexity, we here introduce an index that takes consideration of local paths, with wider horizon than CN. It is defined as\n",
    "$$S^{LP} = A^2 + \\epsilon A^3,$$\n",
    "where $\\epsilon$ is a free parameter. Clearly, this measure degenerates to CN when $\\epsilon = 0$. And if $x$ and $y$ are not directly connected (this is the case we are interested in), $(A^3)_{xy}$ is equal to the number of different paths with length 3 connecting $x$ and $y$. This index can be extended to account for higher-order paths, as\n",
    "$$S^{LP(n)} = A^2 + \\epsilon A^3 + \\epsilon^2 A^4 + \\cdots + \\epsilon^{n-2} A^n,$$\n",
    "where $n > 2$ is the maximal order. With the increasing of $n$, this index asks for more information and computation. Especially, when $n \\rightarrow \\infty$, $S^{LP(n)}$ will be equivalent to the Katz index that takes into account all paths in the network. The computational complexity of this index in an uncorrelated network is $\\mathbb{O}(NâŸ¨kâŸ©^n)$, which grows fast with the increasing of n and will exceed the complexity for calculating the Katz index (approximate to $\\mathbb{O}(N^3)$) for large $n$. Experimental results show that the optimal $n$ is positively correlated with the average shortest distance of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_path_index(folds, subs, epsilon = 0.01, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "        sim = mat.dot(mat) + epsilon*mat.dot(mat.dot(mat))\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ada287e27cfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlocal_path_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'folds' is not defined"
     ]
    }
   ],
   "source": [
    "local_path_index(folds, subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####2. Local Random Walk (LRW)\n",
    "To measure the similarity between nodes $x$ and $y$, a random walker is initially put on node $x$ and thus the initial density vector $\\pi_x(0) = e_x$. This density vector evolves as $\\pi_x(t + 1) = P^T \\pi_x(t)$ for $t \\geq 0$. The LRW index at time step $t$ is thus defined as\n",
    "$$s_{xy}^{LRW} (t) = q_x \\pi_{xy}(t) + q_y \\pi_{yx} (t).$$\n",
    "where $q$ is the initial configuration function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrw_index(folds, subs, c = 0.5, nsteps = 3, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "        dma = np.diagflat(mat.sum(axis = 1))\n",
    "        sim = np.linalg.pinv(dma - mat)\n",
    "        pim = np.identity(len(mat))\n",
    "        pmt = np.identity(len(mat))\n",
    "        es = []\n",
    "        for a in i.nodes():\n",
    "            e = np.zeros(len(mat))\n",
    "            e[a] = 1\n",
    "            es.append(e)\n",
    "            for b in i.nodes():\n",
    "                try:\n",
    "                    nx.shortest_path_length(i, source = a, target = b)\n",
    "                except:\n",
    "                    pmt[a][b] = 0\n",
    "                else:\n",
    "                    if nx.degree(i, a) != 0:\n",
    "                        pmt[a][b] = 1/float(nx.degree(i, a))\n",
    "                    else:\n",
    "                        pmt[a][b] = 0\n",
    "        for n in xrange(nsteps):\n",
    "            pim = (np.transpose(pmt)).dot(pim)\n",
    "        es = np.array(es)\n",
    "        qs = {}\n",
    "        for a in i.nodes():\n",
    "            qs[a] = float(nx.degree(i, a))/float(i.number_of_edges())\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = qs[e[0]]*pim[e[0]][e[1]] + qs[e[1]]*pim[e[1]][e[0]]\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71960588583259388"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrw_index(folds, subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####3. Superposed Random Walk (SRW)\n",
    "Similar to the RWR index, Liu and LuÌˆ proposed the SRW index, where the random walker is continuously released at the starting point, resulting in a higher similarity between the target node and the nodes nearby. The mathematical expression reads\n",
    "$$s_{xy}^{SRW}(t) = \\sum_{\\tau = 1}^t s_{xy}^{LRW} = \\sum_{\\tau = 1}^t q_x \\pi_{xy}(\\tau) + q_y \\pi_{yx} (\\tau),$$\n",
    "where $t$ denotes the time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def srw_index(folds, subs, c = 0.5, nsteps = 3, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "        dma = np.diagflat(mat.sum(axis = 1))\n",
    "        sim = np.linalg.pinv(dma - mat)\n",
    "        pim = np.identity(len(mat))\n",
    "        pmt = np.identity(len(mat))\n",
    "        es = []\n",
    "        for a in i.nodes():\n",
    "            e = np.zeros(len(mat))\n",
    "            e[a] = 1\n",
    "            es.append(e)\n",
    "            for b in i.nodes():\n",
    "                try:\n",
    "                    nx.shortest_path_length(i, source = a, target = b)\n",
    "                except:\n",
    "                    pmt[a][b] = 0\n",
    "                else:\n",
    "                    if nx.degree(i, a) != 0:\n",
    "                        pmt[a][b] = 1/float(nx.degree(i, a))\n",
    "                    else:\n",
    "                        pmt[a][b] = 0\n",
    "        es = np.array(es)\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = 0\n",
    "        qs = {}\n",
    "        for a in i.nodes():\n",
    "            qs[a] = float(nx.degree(i, a))/float(i.number_of_edges())\n",
    "        pim = (np.transpose(pmt)).dot(pim)\n",
    "        for n in xrange(nsteps):\n",
    "            pim = (np.transpose(pmt)).dot(pim)\n",
    "            edges = nx.non_edges(i)\n",
    "            for e in edges:\n",
    "                edgesWithScore[e] += qs[e[0]]*pim[e[0]][e[1]] + qs[e[1]]*pim[e[1]][e[0]]\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71820837030464357"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srw_index(folds, subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_global_and_ql_similarity_indices(G, symmetric = True, nfolds = 10, seed = 0):\n",
    "    random.seed(seed)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    ki = katz_index(folds, subs, symmetric = symmetric)\n",
    "    print 'ki'\n",
    "    lhn2 = lhn2_index(folds, subs, symmetric = symmetric)\n",
    "    print 'lhn2'\n",
    "    act = act_index(folds, subs, symmetric = symmetric)\n",
    "    print 'act'\n",
    "    cbl = cbl_index(folds, subs, symmetric = symmetric)\n",
    "    print 'cbl'\n",
    "    rwr = rwr_index(folds, subs, symmetric = symmetric)\n",
    "    print 'rwr'\n",
    "    mfi = matrix_forest_index(folds, subs, symmetric = symmetric)\n",
    "    print 'mfi'\n",
    "    lpi = local_path_index(folds, subs, symmetric = symmetric)\n",
    "    print 'lpi'\n",
    "    lrw = lrw_index(folds, subs, symmetric = symmetric)\n",
    "    print 'lrw'\n",
    "    srw = srw_index(folds, subs, symmetric = symmetric)\n",
    "    print 'srw'\n",
    "    aucs = {'KI' : ki, \n",
    "            'LHN2' : lhn2, \n",
    "            'ACT' : act, \n",
    "            'CBL' : cbl,\n",
    "            'RWR' : rwr,\n",
    "            'MFI' : mfi,\n",
    "            'LPI' : lpi,\n",
    "            'LRW' : lrw,\n",
    "            'SRW' : srw}\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(columns = ['KI', 'LHN2', 'ACT', 'CBL', 'RWR', 'MFI', 'LPI', 'LRW', 'SRW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc['karate club'] = run_global_and_ql_similarity_indices(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pajek_football = nx.read_pajek('./netws/pajekds/football.net')\n",
    "fixed_pajek_football = nx.Graph(nx.convert_node_labels_to_integers(pajek_football, first_label = 0))\n",
    "df3.loc['pajek football'] = run_global_and_ql_similarity_indices(fixed_pajek_football)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pajek_us_air = nx.read_pajek('./netws/pajekds/USAir97.net')\n",
    "fixed_pajek_us_air = nx.Graph(nx.convert_node_labels_to_integers(pajek_us_air, first_label = 0))\n",
    "df3.loc['pajek_us_air'] = run_global_and_ql_similarity_indices(fixed_pajek_us_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KI</th>\n",
       "      <th>LHN2</th>\n",
       "      <th>ACT</th>\n",
       "      <th>CBL</th>\n",
       "      <th>RWR</th>\n",
       "      <th>MFI</th>\n",
       "      <th>LPI</th>\n",
       "      <th>LRW</th>\n",
       "      <th>SRW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>karate club</th>\n",
       "      <td>0.755191</td>\n",
       "      <td>0.610392</td>\n",
       "      <td>0.665979</td>\n",
       "      <td>0.738737</td>\n",
       "      <td>0.618051</td>\n",
       "      <td>0.748680</td>\n",
       "      <td>0.767460</td>\n",
       "      <td>0.490888</td>\n",
       "      <td>0.453558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pajek football</th>\n",
       "      <td>0.724598</td>\n",
       "      <td>0.521484</td>\n",
       "      <td>0.747681</td>\n",
       "      <td>0.575235</td>\n",
       "      <td>0.746308</td>\n",
       "      <td>0.679982</td>\n",
       "      <td>0.708683</td>\n",
       "      <td>0.435470</td>\n",
       "      <td>0.476082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      KI      LHN2       ACT       CBL       RWR       MFI  \\\n",
       "karate club     0.755191  0.610392  0.665979  0.738737  0.618051  0.748680   \n",
       "pajek football  0.724598  0.521484  0.747681  0.575235  0.746308  0.679982   \n",
       "\n",
       "                     LPI       LRW       SRW  \n",
       "karate club     0.767460  0.490888  0.453558  \n",
       "pajek football  0.708683  0.435470  0.476082  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['CN', 'SaI', 'JI', 'SoI', 'HPI', 'HDI', 'LHN1', 'PAI', 'AAI', 'RAI'])\n",
    "newman_adjnoun = nx.read_gml('./netws/newman/adjnoun/adjnoun.gml')\n",
    "df.loc['newman adjnoun'] = run_local_similarity_indices(newman_adjnoun)\n",
    "newman_celegansneural = nx.read_gml('./netws/newman/celegansneural/celegansneural.gml')\n",
    "fixed_newman_celegansneural = nx.Graph(nx.convert_node_labels_to_integers(newman_celegansneural, first_label = 0))\n",
    "df.loc['newman celegansneural'] = run_local_similarity_indices(fixed_newman_celegansneural)\n",
    "newman_dolphins = nx.read_gml('./netws/newman/dolphins/dolphins.gml')\n",
    "fixed_newman_dolphins = nx.Graph(nx.convert_node_labels_to_integers(newman_dolphins, first_label = 0))\n",
    "df.loc['newman dolphins'] = run_local_similarity_indices(fixed_newman_dolphins)\n",
    "newman_football = nx.read_gml('./netws/newman/football/football.gml')\n",
    "fixed_newman_football = nx.Graph(nx.convert_node_labels_to_integers(newman_football, first_label = 0))\n",
    "df.loc['newman football'] = run_local_similarity_indices(fixed_newman_football)\n",
    "newman_lesmis = nx.read_gml('./netws/newman/lesmis/lesmis.gml')\n",
    "fixed_newman_lesmis = nx.Graph(nx.convert_node_labels_to_integers(newman_lesmis, first_label = 0))\n",
    "df.loc['newman lesmis'] = run_local_similarity_indices(fixed_newman_lesmis)\n",
    "newman_polbooks = nx.read_gml('./netws/newman/polbooks/polbooks.gml')\n",
    "fixed_newman_polbooks = nx.Graph(nx.convert_node_labels_to_integers(newman_polbooks, first_label = 0))\n",
    "df.loc['newman polbooks'] = run_local_similarity_indices(fixed_newman_polbooks)\n",
    "df.loc['karate club'] = run_local_similarity_indices(nx.karate_club_graph())\n",
    "pajek_us_air = nx.read_pajek('./netws/pajekds/USAir97.net')\n",
    "fixed_pajek_us_air = nx.Graph(nx.convert_node_labels_to_integers(pajek_us_air, first_label = 0))\n",
    "df.loc['pajek_us_air'] = run_local_similarity_indices(fixed_pajek_us_air)\n",
    "#newman_netscience = nx.read_gml('./netws/newman/netscience/netscience.gml')\n",
    "#fixed_newman_netscience = nx.Graph(nx.convert_node_labels_to_integers(newman_netscience, first_label = 0))\n",
    "#df.loc['newman netscience'] = run_local_similarity_indices(fixed_newman_netscience)\n",
    "#newman_power = nx.read_gml('./netws/newman/power/power.gml')\n",
    "#fixed_newman_power = nx.Graph(nx.convert_node_labels_to_integers(newman_power, first_label = 0))\n",
    "#df.loc['newman power'] = run_local_similarity_indices(fixed_newman_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CN</th>\n",
       "      <th>SaI</th>\n",
       "      <th>JI</th>\n",
       "      <th>SoI</th>\n",
       "      <th>HPI</th>\n",
       "      <th>HDI</th>\n",
       "      <th>LHN1</th>\n",
       "      <th>PAI</th>\n",
       "      <th>AAI</th>\n",
       "      <th>RAI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>newman adjnoun</th>\n",
       "      <td>0.662143</td>\n",
       "      <td>0.605849</td>\n",
       "      <td>0.603443</td>\n",
       "      <td>0.603443</td>\n",
       "      <td>0.618401</td>\n",
       "      <td>0.602827</td>\n",
       "      <td>0.565677</td>\n",
       "      <td>0.743843</td>\n",
       "      <td>0.661637</td>\n",
       "      <td>0.659071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newman celegansneural</th>\n",
       "      <td>0.843985</td>\n",
       "      <td>0.797159</td>\n",
       "      <td>0.789971</td>\n",
       "      <td>0.789971</td>\n",
       "      <td>0.804574</td>\n",
       "      <td>0.779009</td>\n",
       "      <td>0.725389</td>\n",
       "      <td>0.750079</td>\n",
       "      <td>0.861112</td>\n",
       "      <td>0.866068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newman dolphins</th>\n",
       "      <td>0.779455</td>\n",
       "      <td>0.774381</td>\n",
       "      <td>0.778577</td>\n",
       "      <td>0.778577</td>\n",
       "      <td>0.763214</td>\n",
       "      <td>0.780667</td>\n",
       "      <td>0.762055</td>\n",
       "      <td>0.619125</td>\n",
       "      <td>0.781451</td>\n",
       "      <td>0.780727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newman football</th>\n",
       "      <td>0.845945</td>\n",
       "      <td>0.857528</td>\n",
       "      <td>0.857887</td>\n",
       "      <td>0.857887</td>\n",
       "      <td>0.855511</td>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.859482</td>\n",
       "      <td>0.269802</td>\n",
       "      <td>0.845795</td>\n",
       "      <td>0.845755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newman lesmis</th>\n",
       "      <td>0.910810</td>\n",
       "      <td>0.882181</td>\n",
       "      <td>0.879710</td>\n",
       "      <td>0.879710</td>\n",
       "      <td>0.847450</td>\n",
       "      <td>0.878189</td>\n",
       "      <td>0.820271</td>\n",
       "      <td>0.776403</td>\n",
       "      <td>0.918360</td>\n",
       "      <td>0.918733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newman polbooks</th>\n",
       "      <td>0.887208</td>\n",
       "      <td>0.884445</td>\n",
       "      <td>0.875319</td>\n",
       "      <td>0.875319</td>\n",
       "      <td>0.894284</td>\n",
       "      <td>0.863075</td>\n",
       "      <td>0.847957</td>\n",
       "      <td>0.653248</td>\n",
       "      <td>0.897115</td>\n",
       "      <td>0.899760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karate club</th>\n",
       "      <td>0.699908</td>\n",
       "      <td>0.636143</td>\n",
       "      <td>0.606829</td>\n",
       "      <td>0.606829</td>\n",
       "      <td>0.712276</td>\n",
       "      <td>0.592641</td>\n",
       "      <td>0.599922</td>\n",
       "      <td>0.711626</td>\n",
       "      <td>0.725595</td>\n",
       "      <td>0.733396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pajek_us_air</th>\n",
       "      <td>0.934056</td>\n",
       "      <td>0.907940</td>\n",
       "      <td>0.897406</td>\n",
       "      <td>0.897406</td>\n",
       "      <td>0.869254</td>\n",
       "      <td>0.890794</td>\n",
       "      <td>0.766953</td>\n",
       "      <td>0.885312</td>\n",
       "      <td>0.945331</td>\n",
       "      <td>0.951237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             CN       SaI        JI       SoI       HPI  \\\n",
       "newman adjnoun         0.662143  0.605849  0.603443  0.603443  0.618401   \n",
       "newman celegansneural  0.843985  0.797159  0.789971  0.789971  0.804574   \n",
       "newman dolphins        0.779455  0.774381  0.778577  0.778577  0.763214   \n",
       "newman football        0.845945  0.857528  0.857887  0.857887  0.855511   \n",
       "newman lesmis          0.910810  0.882181  0.879710  0.879710  0.847450   \n",
       "newman polbooks        0.887208  0.884445  0.875319  0.875319  0.894284   \n",
       "karate club            0.699908  0.636143  0.606829  0.606829  0.712276   \n",
       "pajek_us_air           0.934056  0.907940  0.897406  0.897406  0.869254   \n",
       "\n",
       "                            HDI      LHN1       PAI       AAI       RAI  \n",
       "newman adjnoun         0.602827  0.565677  0.743843  0.661637  0.659071  \n",
       "newman celegansneural  0.779009  0.725389  0.750079  0.861112  0.866068  \n",
       "newman dolphins        0.780667  0.762055  0.619125  0.781451  0.780727  \n",
       "newman football        0.857384  0.859482  0.269802  0.845795  0.845755  \n",
       "newman lesmis          0.878189  0.820271  0.776403  0.918360  0.918733  \n",
       "newman polbooks        0.863075  0.847957  0.653248  0.897115  0.899760  \n",
       "karate club            0.592641  0.599922  0.711626  0.725595  0.733396  \n",
       "pajek_us_air           0.890794  0.766953  0.885312  0.945331  0.951237  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('local_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(columns = ['KI', 'LHN2', 'ACT', 'CBL', 'RWR', 'MFI', 'LPI', 'LRW', 'SRW'])\n",
    "newman_adjnoun = nx.read_gml('./netws/newman/adjnoun/adjnoun.gml')\n",
    "df3.loc['newman adjnoun'] = run_global_and_ql_similarity_indices(newman_adjnoun)\n",
    "newman_celegansneural = nx.read_gml('./netws/newman/celegansneural/celegansneural.gml')\n",
    "fixed_newman_celegansneural = nx.Graph(nx.convert_node_labels_to_integers(newman_celegansneural, first_label = 0))\n",
    "df3.loc['newman celegansneural'] = run_global_and_ql_similarity_indices(fixed_newman_celegansneural)\n",
    "newman_dolphins = nx.read_gml('./netws/newman/dolphins/dolphins.gml')\n",
    "fixed_newman_dolphins = nx.Graph(nx.convert_node_labels_to_integers(newman_dolphins, first_label = 0))\n",
    "df3.loc['newman dolphins'] = run_global_and_ql_similarity_indices(fixed_newman_dolphins)\n",
    "newman_football = nx.read_gml('./netws/newman/football/football.gml')\n",
    "fixed_newman_football = nx.Graph(nx.convert_node_labels_to_integers(newman_football, first_label = 0))\n",
    "df3.loc['newman football'] = run_global_and_ql_similarity_indices(fixed_newman_football)\n",
    "newman_lesmis = nx.read_gml('./netws/newman/lesmis/lesmis.gml')\n",
    "fixed_newman_lesmis = nx.Graph(nx.convert_node_labels_to_integers(newman_lesmis, first_label = 0))\n",
    "df3.loc['newman lesmis'] = run_global_and_ql_similarity_indices(fixed_newman_lesmis)\n",
    "newman_polbooks = nx.read_gml('./netws/newman/polbooks/polbooks.gml')\n",
    "fixed_newman_polbooks = nx.Graph(nx.convert_node_labels_to_integers(newman_polbooks, first_label = 0))\n",
    "df3.loc['newman polbooks'] = run_global_and_ql_similarity_indices(fixed_newman_polbooks)\n",
    "df3.loc['karate club'] = run_global_and_ql_similarity_indices(nx.karate_club_graph())\n",
    "pajek_us_air = nx.read_pajek('./netws/pajekds/USAir97.net')\n",
    "fixed_pajek_us_air = nx.Graph(nx.convert_node_labels_to_integers(pajek_us_air, first_label = 0))\n",
    "df3.loc['pajek_us_air'] = run_global_and_ql_similarity_indices(fixed_pajek_us_air)\n",
    "#newman_netscience = nx.read_gml('./netws/newman/netscience/netscience.gml')\n",
    "#fixed_newman_netscience = nx.Graph(nx.convert_node_labels_to_integers(newman_netscience, first_label = 0))\n",
    "#df3.loc['newman netscience'] = run_global_and_ql_similarity_indices(fixed_newman_netscience)\n",
    "#newman_power = nx.read_gml('./netws/newman/power/power.gml')\n",
    "#fixed_newman_power = nx.Graph(nx.convert_node_labels_to_integers(newman_power, first_label = 0))\n",
    "#df3.loc['newman power'] = run_global_and_ql_similarity_indices(fixed_newman_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KI</th>\n",
       "      <th>LHN2</th>\n",
       "      <th>ACT</th>\n",
       "      <th>CBL</th>\n",
       "      <th>RWR</th>\n",
       "      <th>MFI</th>\n",
       "      <th>LPI</th>\n",
       "      <th>LRW</th>\n",
       "      <th>SRW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>newman adjnoun</th>\n",
       "      <td>0.713803</td>\n",
       "      <td>0.548633</td>\n",
       "      <td>0.742174</td>\n",
       "      <td>0.586133</td>\n",
       "      <td>0.737660</td>\n",
       "      <td>0.667497</td>\n",
       "      <td>0.711011</td>\n",
       "      <td>0.503706</td>\n",
       "      <td>0.504239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newman celegansneural</th>\n",
       "      <td>0.851641</td>\n",
       "      <td>0.716973</td>\n",
       "      <td>0.738247</td>\n",
       "      <td>0.848005</td>\n",
       "      <td>0.724508</td>\n",
       "      <td>0.865206</td>\n",
       "      <td>0.860138</td>\n",
       "      <td>0.520710</td>\n",
       "      <td>0.520800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newman dolphins</th>\n",
       "      <td>0.798655</td>\n",
       "      <td>0.825203</td>\n",
       "      <td>0.759587</td>\n",
       "      <td>0.790693</td>\n",
       "      <td>0.648643</td>\n",
       "      <td>0.804328</td>\n",
       "      <td>0.798704</td>\n",
       "      <td>0.387617</td>\n",
       "      <td>0.387909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newman football</th>\n",
       "      <td>0.856571</td>\n",
       "      <td>0.878944</td>\n",
       "      <td>0.587787</td>\n",
       "      <td>0.884727</td>\n",
       "      <td>0.272704</td>\n",
       "      <td>0.878457</td>\n",
       "      <td>0.858313</td>\n",
       "      <td>0.526725</td>\n",
       "      <td>0.522299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newman lesmis</th>\n",
       "      <td>0.883969</td>\n",
       "      <td>0.813227</td>\n",
       "      <td>0.862551</td>\n",
       "      <td>0.824819</td>\n",
       "      <td>0.793631</td>\n",
       "      <td>0.867104</td>\n",
       "      <td>0.895480</td>\n",
       "      <td>0.350594</td>\n",
       "      <td>0.349364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newman polbooks</th>\n",
       "      <td>0.890985</td>\n",
       "      <td>0.858069</td>\n",
       "      <td>0.728527</td>\n",
       "      <td>0.890554</td>\n",
       "      <td>0.618080</td>\n",
       "      <td>0.898542</td>\n",
       "      <td>0.895760</td>\n",
       "      <td>0.615408</td>\n",
       "      <td>0.616160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karate club</th>\n",
       "      <td>0.755191</td>\n",
       "      <td>0.610392</td>\n",
       "      <td>0.665979</td>\n",
       "      <td>0.738737</td>\n",
       "      <td>0.618051</td>\n",
       "      <td>0.748680</td>\n",
       "      <td>0.767460</td>\n",
       "      <td>0.735128</td>\n",
       "      <td>0.735585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pajek_us_air</th>\n",
       "      <td>0.919685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.892469</td>\n",
       "      <td>0.912580</td>\n",
       "      <td>0.862015</td>\n",
       "      <td>0.913495</td>\n",
       "      <td>0.926268</td>\n",
       "      <td>0.459583</td>\n",
       "      <td>0.459708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             KI      LHN2       ACT       CBL       RWR  \\\n",
       "newman adjnoun         0.713803  0.548633  0.742174  0.586133  0.737660   \n",
       "newman celegansneural  0.851641  0.716973  0.738247  0.848005  0.724508   \n",
       "newman dolphins        0.798655  0.825203  0.759587  0.790693  0.648643   \n",
       "newman football        0.856571  0.878944  0.587787  0.884727  0.272704   \n",
       "newman lesmis          0.883969  0.813227  0.862551  0.824819  0.793631   \n",
       "newman polbooks        0.890985  0.858069  0.728527  0.890554  0.618080   \n",
       "karate club            0.755191  0.610392  0.665979  0.738737  0.618051   \n",
       "pajek_us_air           0.919685       NaN  0.892469  0.912580  0.862015   \n",
       "\n",
       "                            MFI       LPI       LRW       SRW  \n",
       "newman adjnoun         0.667497  0.711011  0.503706  0.504239  \n",
       "newman celegansneural  0.865206  0.860138  0.520710  0.520800  \n",
       "newman dolphins        0.804328  0.798704  0.387617  0.387909  \n",
       "newman football        0.878457  0.858313  0.526725  0.522299  \n",
       "newman lesmis          0.867104  0.895480  0.350594  0.349364  \n",
       "newman polbooks        0.898542  0.895760  0.615408  0.616160  \n",
       "karate club            0.748680  0.767460  0.735128  0.735585  \n",
       "pajek_us_air           0.913495  0.926268  0.459583  0.459708  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.to_csv('global_8.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks horrible, so now I'll try to run these algorithms with different parameters to determine wheter the problem is in them or in me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_ki_parameters(G, nfolds = 10, symmetric = True):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    for x in np.arange(0.0, 0.1, 0.01):\n",
    "        print 'beta =', x, 'ki =', katz_index(folds, subs, beta = x, symmetric = symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta = 0.0 ki = beta = 0.0424672940958\n",
      "0.714193555204\n",
      "beta = 0.01 ki = 0.70911876278\n",
      "beta = 0.02 ki = 0.709056459665\n",
      "beta = 0.03 ki = 0.709854467342\n",
      "beta = 0.04 ki = 0.713057082696\n",
      "beta = 0.05 ki = 0.717388134068\n",
      "beta = 0.06 ki = 0.721526534377\n",
      "beta = 0.07 ki = 0.72536735508\n",
      "beta = 0.08 ki = 0.727500620067\n",
      "beta = 0.09 ki = 0.273487294505\n"
     ]
    }
   ],
   "source": [
    "newman_adjnoun = nx.read_gml('./netws/newman/adjnoun/adjnoun.gml')\n",
    "test_ki_parameters(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta = 0.0 ki = beta = 0.0227554511203\n",
      "0.851494478687\n",
      "beta = 0.01 ki = 0.857351310241\n",
      "beta = 0.02 ki = 0.853666493053\n",
      "beta = 0.03 ki = 0.838944575228\n",
      "beta = 0.04 ki = 0.785807342633\n",
      "beta = 0.05 ki = 0.407758088476\n",
      "beta = 0.06 ki ="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:9: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-0550dd49f6fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnewman_celegansneural\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./netws/newman/celegansneural/celegansneural.gml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfixed_newman_celegansneural\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_node_labels_to_integers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewman_celegansneural\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_ki_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_newman_celegansneural\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-4530ba0238b8>\u001b[0m in \u001b[0;36mtest_ki_parameters\u001b[0;34m(G, nfolds, symmetric)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msubs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'beta ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ki ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkatz_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-b49836d121de>\u001b[0m in \u001b[0;36mkatz_index\u001b[0;34m(folds, subs, beta, symmetric, nfolds)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0medgesWithScore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0medgesWithScore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                         \u001b[0mhighScore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0medgesWithScore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0medgesWithScore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "newman_celegansneural = nx.read_gml('./netws/newman/celegansneural/celegansneural.gml')\n",
    "fixed_newman_celegansneural = nx.Graph(nx.convert_node_labels_to_integers(newman_celegansneural, first_label = 0))\n",
    "test_ki_parameters(fixed_newman_celegansneural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " beta = 0.0 ki = beta = 0.0747952266029\n",
      "0.798667965743\n",
      "beta = 0.01 ki = 0.801108063895\n",
      "beta = 0.02 ki = 0.801059348537\n",
      "beta = 0.03 ki = 0.801002092956\n",
      "beta = 0.04 ki = 0.800906707082\n",
      "beta = 0.05 ki = 0.800606957275\n",
      "beta = 0.06 ki = 0.799948878945\n",
      "beta = 0.07 ki = 0.79913491147\n",
      "beta = 0.08 ki = 0.798019149346\n",
      "beta = 0.09 ki = 0.796173258276\n"
     ]
    }
   ],
   "source": [
    "newman_dolphins = nx.read_gml('./netws/newman/dolphins/dolphins.gml')\n",
    "fixed_newman_dolphins = nx.Graph(nx.convert_node_labels_to_integers(newman_dolphins, first_label = 0))\n",
    "test_ki_parameters(fixed_newman_dolphins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta = 0.0 ki = beta = 0.0779410913728\n",
      "0.755503179533\n",
      "beta = 0.01 ki = 0.762352114759\n",
      "beta = 0.02 ki = 0.76205079858\n",
      "beta = 0.03 ki = 0.761950976043\n",
      "beta = 0.04 ki = 0.761189367051\n",
      "beta = 0.05 ki = 0.760002587992\n",
      "beta = 0.06 ki = 0.759032091097\n",
      "beta = 0.07 ki = 0.756762052647\n",
      "beta = 0.08 ki = 0.755225894706\n",
      "beta = 0.09 ki = 0.753179532683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:9: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "test_ki_parameters(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see, that in Katz index the beta is selected more or less optimally by default, so no reason to mess with it. Let's check parameters for other algs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_LHN2_parameters(G, nfolds = 10, symmetric = True):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    for x in np.arange(0.1, 1.0, 0.1):\n",
    "        print 'phi =', x, 'lhn2 =', lhn2_index(folds, subs, phi = x, symmetric = symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi = 0.1 lhn2 = 0.578737044327\n",
      "phi = 0.2 lhn2 = 0.574619359135\n",
      "phi = 0.3 lhn2 = 0.567480747324\n",
      "phi = 0.4 lhn2 = 0.558441010825\n",
      "phi = 0.5 lhn2 = 0.548633385559\n",
      "phi = 0.6 lhn2 = 0.537664222159\n",
      "phi = 0.7 lhn2 = 0.525860382504\n",
      "phi = 0.8 lhn2 = 0.514851586444\n",
      "phi = 0.9 lhn2 = 0.506158504251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "test_LHN2_parameters(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi = 0.1 lhn2 = 0.732686578289\n",
      "phi = 0.2 lhn2 = 0.732088550984\n",
      "phi = 0.3 lhn2 = 0.729652803736\n",
      "phi = 0.4 lhn2 = 0.724964789202\n",
      "phi = 0.5 lhn2 = 0.716973022855\n",
      "phi = 0.6 lhn2 = 0.704023042213\n",
      "phi = 0.7 lhn2 = 0.68389392483\n",
      "phi = 0.8 lhn2 = 0.65116523821\n",
      "phi = 0.9 lhn2 = 0.591313001184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "test_LHN2_parameters(fixed_newman_celegansneural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi = 0.1 lhn2 = 0.824121439569\n",
      "phi = 0.2 lhn2 = 0.824804416859\n",
      "phi = 0.3 lhn2 = 0.825773672055\n",
      "phi = 0.4 lhn2 = 0.825869899923\n",
      "phi = 0.5 lhn2 = 0.825203040801\n",
      "phi = 0.6 lhn2 = 0.824208525789\n",
      "phi = 0.7 lhn2 = 0.821811970747\n",
      "phi = 0.8 lhn2 = 0.811610854503\n",
      "phi = 0.9 lhn2 = 0.780332467283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "test_LHN2_parameters(fixed_newman_dolphins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi = 0.1 lhn2 = 0.624948650958\n",
      "phi = 0.2 lhn2 = 0.625063672812\n",
      "phi = 0.3 lhn2 = 0.622909067008\n",
      "phi = 0.4 lhn2 = 0.618460186007\n",
      "phi = 0.5 lhn2 = 0.610392224523\n",
      "phi = 0.6 lhn2 = 0.60114118111\n",
      "phi = 0.7 lhn2 = 0.578338098524\n",
      "phi = 0.8 lhn2 = 0.535695800059\n",
      "phi = 0.9 lhn2 = 0.463061553124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "test_LHN2_parameters(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in these networks we're better off setting phi very low.\n",
    "I guess it is because these are really small networks with small diameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test_rwr_parameters(G, nfolds = 10, symmetric = True):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    for x in np.arange(0.1, 1.0, 0.1):\n",
    "        print 'c =', x, 'rwr =', rwr_index(folds, subs, c = x, symmetric = symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 0.1 rwr = 0.737925262269\n",
      "c = 0.2 rwr = 0.737688441586\n",
      "c = 0.3 rwr = 0.737668371875\n",
      "c = 0.4 rwr = 0.737842903784\n",
      "c = 0.5 rwr = 0.737659575241\n",
      "c = 0.6 rwr = 0.7377518395\n",
      "c = 0.7 rwr = 0.737769710053\n",
      "c = 0.8 rwr = 0.737656018341\n",
      "c = 0.9 rwr = 0.737857867623\n"
     ]
    }
   ],
   "source": [
    "test_rwr_parameters(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 0.1 rwr = 0.617004954156\n",
      "c = 0.2 rwr = 0.615954968944\n",
      "c = 0.3 rwr = 0.617478186927\n",
      "c = 0.4 rwr = 0.618927462289\n",
      "c = 0.5 rwr = 0.618051242236\n",
      "c = 0.6 rwr = 0.614758947057\n",
      "c = 0.7 rwr = 0.613283791778\n",
      "c = 0.8 rwr = 0.61529318249\n",
      "c = 0.9 rwr = 0.616906980183\n"
     ]
    }
   ],
   "source": [
    "test_rwr_parameters(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " c = 0.1 rwr = 0.648886403002\n",
      "c = 0.2 rwr = 0.649530408006\n",
      "c = 0.3 rwr = 0.650545010585\n",
      "c = 0.4 rwr = 0.647964900885\n",
      "c = 0.5 rwr = 0.648642946497\n",
      "c = 0.6 rwr = 0.648778627791\n",
      "c = 0.7 rwr = 0.648418855851\n",
      "c = 0.8 rwr = 0.649808506543\n",
      "c = 0.9 rwr = 0.649468822171\n"
     ]
    }
   ],
   "source": [
    "test_rwr_parameters(fixed_newman_dolphins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newman_celegansneural = nx.read_gml('./netws/newman/celegansneural/celegansneural.gml')\n",
    "fixed_newman_celegansneural = nx.Graph(nx.convert_node_labels_to_integers(newman_celegansneural, first_label = 0))\n",
    "test_rwr_parameters(fixed_newman_celegansneural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the difference is really negligible, less than 1% of AUC depending on the probability c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_mfi_parameters(G, nfolds = 10, symmetric = True):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    for x in np.arange(0.1, 1.0, 0.1):\n",
    "        print 'alpha =', x, 'mfi =', matrix_forest_index(folds, subs, alpha = x, symmetric = symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.1 mfi = 0.725042517007\n",
      "alpha = 0.2 mfi = 0.729290520556\n",
      "alpha = 0.3 mfi = 0.733459035788\n",
      "alpha = 0.4 mfi = 0.735828896776\n",
      "alpha = 0.5 mfi = 0.738636867791\n",
      "alpha = 0.6 mfi = 0.741873706004\n",
      "alpha = 0.7 mfi = 0.743060485064\n",
      "alpha = 0.8 mfi = 0.745239943804\n",
      "alpha = 0.9 mfi = 0.747167997634\n"
     ]
    }
   ],
   "source": [
    "test_mfi_parameters(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.1 mfi = 0.683884920523\n",
      "alpha = 0.2 mfi = 0.67873380774\n",
      "alpha = 0.3 mfi = 0.675787858083\n",
      "alpha = 0.4 mfi = 0.673737850367\n",
      "alpha = 0.5 mfi = 0.672186587887\n",
      "alpha = 0.6 mfi = 0.670956182628\n",
      "alpha = 0.7 mfi = 0.669931848079\n",
      "alpha = 0.8 mfi = 0.668968339385\n",
      "alpha = 0.9 mfi = 0.668228561599\n"
     ]
    }
   ],
   "source": [
    "newman_adjnoun = nx.read_gml('./netws/newman/adjnoun/adjnoun.gml')\n",
    "test_mfi_parameters(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.1 mfi = 0.806066445343\n",
      "alpha = 0.2 mfi = 0.807392585643\n",
      "alpha = 0.3 mfi = 0.807964179176\n",
      "alpha = 0.4 mfi = 0.807716873557\n",
      "alpha = 0.5 mfi = 0.807332202656\n",
      "alpha = 0.6 mfi = 0.806841801386\n",
      "alpha = 0.7 mfi = 0.806178069669\n",
      "alpha = 0.8 mfi = 0.805612249808\n",
      "alpha = 0.9 mfi = 0.804919409161\n"
     ]
    }
   ],
   "source": [
    "newman_dolphins = nx.read_gml('./netws/newman/dolphins/dolphins.gml')\n",
    "fixed_newman_dolphins = nx.Graph(nx.convert_node_labels_to_integers(newman_dolphins, first_label = 0))\n",
    "test_mfi_parameters(fixed_newman_dolphins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.1 mfi = 0.876153704075\n",
      "alpha = 0.2 mfi = 0.874984559048\n",
      "alpha = 0.3 mfi = 0.873089675743\n",
      "alpha = 0.4 mfi = 0.871391548539\n",
      "alpha = 0.5 mfi = 0.869939201837\n",
      "alpha = 0.6 mfi = 0.868715130648\n",
      "alpha = 0.7 mfi = 0.867656304131\n",
      "alpha = 0.8 mfi = 0.866729094208\n",
      "alpha = 0.9 mfi = 0.865918542153\n"
     ]
    }
   ],
   "source": [
    "newman_celegansneural = nx.read_gml('./netws/newman/celegansneural/celegansneural.gml')\n",
    "fixed_newman_celegansneural = nx.Graph(nx.convert_node_labels_to_integers(newman_celegansneural, first_label = 0))\n",
    "test_mfi_parameters(fixed_newman_celegansneural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, difference is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_lpi_parameters(G, nfolds = 10, symmetric = True):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    for x in np.arange(0.1, 1.0, 0.1):\n",
    "        print 'epsilon =', x, 'lpi =', local_path_index(folds, subs, epsilon = x, symmetric = symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon = 0.1 lpi = 0.767563220941\n",
      "epsilon = 0.2 lpi = 0.777645297249\n",
      "epsilon = 0.3 lpi = 0.786348343685\n",
      "epsilon = 0.4 lpi = 0.793415409642\n",
      "epsilon = 0.5 lpi = 0.796328748891\n",
      "epsilon = 0.6 lpi = 0.79909790003\n",
      "epsilon = 0.7 lpi = 0.800112762496\n",
      "epsilon = 0.8 lpi = 0.800164522331\n",
      "epsilon = 0.9 lpi = 0.800138642413\n"
     ]
    }
   ],
   "source": [
    "test_lpi_parameters(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon = 0.1 lpi = 0.723985207886\n",
      "epsilon = 0.2 lpi = 0.73314760962\n",
      "epsilon = 0.3 lpi = 0.736963245178\n",
      "epsilon = 0.4 lpi = 0.739373379435\n",
      "epsilon = 0.5 lpi = 0.740622998646\n",
      "epsilon = 0.6 lpi = 0.741688749086\n",
      "epsilon = 0.7 lpi = 0.741943282556\n",
      "epsilon = 0.8 lpi = 0.742057375853\n",
      "epsilon = 0.9 lpi = 0.742080825576\n"
     ]
    }
   ],
   "source": [
    "test_lpi_parameters(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon = 0.1 lpi = 0.798449287914\n",
      "epsilon = 0.2 lpi = 0.795915728445\n",
      "epsilon = 0.3 lpi = 0.793940531178\n",
      "epsilon = 0.4 lpi = 0.791173739415\n",
      "epsilon = 0.5 lpi = 0.789054200346\n",
      "epsilon = 0.6 lpi = 0.786994202271\n",
      "epsilon = 0.7 lpi = 0.785792556774\n",
      "epsilon = 0.8 lpi = 0.785698494034\n",
      "epsilon = 0.9 lpi = 0.785691276944\n"
     ]
    }
   ],
   "source": [
    "test_lpi_parameters(fixed_newman_dolphins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon = 0.1 lpi = 0.859075866649\n",
      "epsilon = 0.2 lpi = 0.853313697352\n",
      "epsilon = 0.3 lpi = 0.84959694307\n",
      "epsilon = 0.4 lpi = 0.846944121497\n",
      "epsilon = 0.5 lpi = 0.845116491745\n",
      "epsilon = 0.6 lpi = 0.843707928423\n",
      "epsilon = 0.7 lpi = 0.842596333147\n",
      "epsilon = 0.8 lpi = 0.842131553608\n",
      "epsilon = 0.9 lpi = 0.841975797335\n"
     ]
    }
   ],
   "source": [
    "test_lpi_parameters(fixed_newman_celegansneural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference within 2% of AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_lrw_parameters(G, nfolds = 10, symmetric = True):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    for x in np.arange(1, 10, 1):\n",
    "        print 'nsteps =', x, 'lrw =', lrw_index(folds, subs, nsteps = x, symmetric = symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsteps = 1 lrw = 0.735926870748\n",
      "nsteps = 2 lrw = 0.734102336587\n",
      "nsteps = 3 lrw = 0.735128290447\n",
      "nsteps = 4 lrw = 0.735533126294\n",
      "nsteps = 5 lrw = 0.737133984028\n",
      "nsteps = 6 lrw = 0.736819727891\n",
      "nsteps = 7 lrw = 0.736692176871\n",
      "nsteps = 8 lrw = 0.734152247856\n",
      "nsteps = 9 lrw = 0.737206078083\n"
     ]
    }
   ],
   "source": [
    "test_lrw_parameters(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsteps = 1 lrw = 0.505026845988\n",
      "nsteps = 2 lrw = 0.50448122521\n",
      "nsteps = 3 lrw = 0.503705988385\n",
      "nsteps = 4 lrw = 0.504238571977\n",
      "nsteps = 5 lrw = 0.503753762712\n",
      "nsteps = 6 lrw = 0.50397049456\n",
      "nsteps = 7 lrw = 0.503905265608\n",
      "nsteps = 8 lrw = 0.504010079413\n",
      "nsteps = 9 lrw = 0.504263479837\n"
     ]
    }
   ],
   "source": [
    "test_lrw_parameters(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsteps = 1 lrw = 0.386032645304\n",
      "nsteps = 2 lrw = 0.383901679176\n",
      "nsteps = 3 lrw = 0.387616676289\n",
      "nsteps = 4 lrw = 0.387750072171\n",
      "nsteps = 5 lrw = 0.388715598537\n",
      "nsteps = 6 lrw = 0.387777857968\n",
      "nsteps = 7 lrw = 0.387418807737\n",
      "nsteps = 8 lrw = 0.387173186105\n",
      "nsteps = 9 lrw = 0.387570126059\n"
     ]
    }
   ],
   "source": [
    "test_lrw_parameters(fixed_newman_dolphins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsteps = 1 lrw = 0.52063825636\n",
      "nsteps = 2 lrw = 0.520688899948\n",
      "nsteps = 3 lrw = 0.52071049477\n",
      "nsteps = 4 lrw = 0.520804255404\n",
      "nsteps = 5 lrw = 0.520760717919\n",
      "nsteps = 6 lrw = 0.520642898367\n",
      "nsteps = 7 lrw = 0.520693766951\n",
      "nsteps = 8 lrw = 0.520682248569\n",
      "nsteps = 9 lrw = 0.520755233371\n"
     ]
    }
   ],
   "source": [
    "test_lrw_parameters(fixed_newman_celegansneural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_srw_parameters(G, nfolds = 10, symmetric = True):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    for x in np.arange(1, 10, 1):\n",
    "        print 'nsteps =', x, 'srw =', srw_index(folds, subs, nsteps = x, symmetric = symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsteps = 1 srw = 0.734102336587\n",
      "nsteps = 2 srw = 0.735102410529\n",
      "nsteps = 3 srw = 0.735584886128\n",
      "nsteps = 4 srw = 0.73693988465\n",
      "nsteps = 5 srw = 0.736806787933\n",
      "nsteps = 6 srw = 0.736899216208\n",
      "nsteps = 7 srw = 0.734048728187\n",
      "nsteps = 8 srw = 0.736902913339\n",
      "nsteps = 9 srw = 0.736821576457\n"
     ]
    }
   ],
   "source": [
    "test_srw_parameters(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsteps = 1 srw = 0.50448122521\n",
      "nsteps = 2 srw = 0.503745329418\n",
      "nsteps = 3 srw = 0.504238777551\n",
      "nsteps = 4 srw = 0.503812996568\n",
      "nsteps = 5 srw = 0.50391196826\n",
      "nsteps = 6 srw = 0.503895001275\n",
      "nsteps = 7 srw = 0.504011886547\n",
      "nsteps = 8 srw = 0.504261672703\n",
      "nsteps = 9 srw = 0.504728018598\n"
     ]
    }
   ],
   "source": [
    "test_srw_parameters(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsteps = 1 srw = 0.383901679176\n",
      "nsteps = 2 srw = 0.387587807929\n",
      "nsteps = 3 srw = 0.387908848152\n",
      "nsteps = 4 srw = 0.388715598537\n",
      "nsteps = 5 srw = 0.387754402425\n",
      "nsteps = 6 srw = 0.387445871824\n",
      "nsteps = 7 srw = 0.387075755389\n",
      "nsteps = 8 srw = 0.387613548884\n",
      "nsteps = 9 srw = 0.38803442552\n"
     ]
    }
   ],
   "source": [
    "test_srw_parameters(fixed_newman_dolphins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried out some other indices, AUC is pretty bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assort_pindex(folds, subs, symmetric = True, nfolds = 10):\n",
    "    nmis = len(folds[0])\n",
    "    step = 0\n",
    "    auc = []\n",
    "    for i in subs:\n",
    "        edgesWithScore = {}\n",
    "        edges = nx.non_edges(i)\n",
    "        a = nx.average_clustering(i)\n",
    "        for e in edges:\n",
    "            i.add_edge(*e)\n",
    "            edgesWithScore[e] = abs(a - nx.average_clustering(i))\n",
    "            i.remove_edge(*e)\n",
    "        highScore = 0\n",
    "        sameScore = 0\n",
    "        allScore = 0\n",
    "        for e in edgesWithScore:\n",
    "            if e not in folds[step]:\n",
    "                for s in folds[step]:\n",
    "                    if edgesWithScore[e] < edgesWithScore[s]:\n",
    "                        highScore += 1\n",
    "                    elif edgesWithScore[e] == edgesWithScore[s]:\n",
    "                        sameScore += 1\n",
    "                    allScore += 1\n",
    "        auc.append(float(highScore + 0.5*sameScore)/float(allScore))\n",
    "        step += 1\n",
    "\n",
    "    return np.mean(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_assort_pindex(G, nfolds = 10, symmetric = True):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    print assort_pindex(folds, subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.522409295709\n"
     ]
    }
   ],
   "source": [
    "newman_adjnoun = nx.read_gml('./netws/newman/adjnoun/adjnoun.gml')\n",
    "test_assort_pindex(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.578083407276\n"
     ]
    }
   ],
   "source": [
    "test_assort_pindex(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Scikit-learn\n",
    "\n",
    "So now i'm going to try to build dataset of all edges that are not in the initial graph, then calculate all the indices for these edges and then try to classify these into two classes of 'edges that were removed' and 'edges that never were there'.\n",
    "\n",
    "Then I'm going to use scikit-learn random forest to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def common_neighbours(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = mat[e[0]][e[1]]\n",
    "    return edgesWithScore \n",
    "\n",
    "def salton_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(np.sqrt(j * k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def jaccard_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        if nx.degree(i, e[0]) != 0 or nx.degree(i, e[1]) != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(len(set(i[e[0]])|set(i[e[1]])))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def sorensen_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 or k != 0:\n",
    "            edgesWithScore[e] = 2*float(mat[e[0]][e[1]])/float(j + k)\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def hub_promoted_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(min(j, k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def hub_depressed_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 or k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(max(j, k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def LHN1_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(j * k)\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def preferential_attachment_index(sub):\n",
    "    i = sub\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = nx.degree(i, e[0]) * nx.degree(i, e[1])\n",
    "    return edgesWithScore\n",
    "\n",
    "def adamic_adar_index(sub):\n",
    "    i = sub\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = np.sum(1/np.log(nx.degree(i, sorted(nx.common_neighbors(i, e[0], e[1]))).values()))\n",
    "    return edgesWithScore\n",
    "\n",
    "def resource_allocation_index(sub):\n",
    "    i = sub\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = np.sum(1/np.array(\n",
    "                nx.degree(i, sorted(nx.common_neighbors(i, e[0], e[1]))).values()).astype(float))\n",
    "    return edgesWithScore\n",
    "\n",
    "def katz_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    ide = np.identity(len(mat))\n",
    "    beta = (1/float(max(np.linalg.eig(mat)[0])))/2\n",
    "    sim = np.linalg.inv(ide - beta*mat) - ide\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def lhn2_index(sub, phi = 0.1):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    ide = np.identity(len(mat))\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = 0\n",
    "    if np.linalg.det(dma) != 0:\n",
    "        lambd = float(max(np.linalg.eig(mat)[0]))\n",
    "        sim = (2 * i.number_of_edges() * lambd * np.linalg.inv(dma)).dot(np.linalg.inv(\n",
    "        ide - (phi/lambd) * mat)).dot(np.linalg.inv(dma))\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def act_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    sim = np.linalg.pinv(dma - mat)\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        if sim[e[0]][e[0]] + sim[e[1]][e[1]] - 2*sim[e[0]][e[1]] != 0:\n",
    "            edgesWithScore[e] = 1/float(sim[e[0]][e[0]] + sim[e[1]][e[1]] - 2*sim[e[0]][e[1]])\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def cbl_index(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    sim = np.linalg.pinv(dma - mat)\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        if sim[e[0]][e[0]] * sim[e[1]][e[1]] != 0:\n",
    "            edgesWithScore[e] = float(sim[e[0]][e[1]])/np.sqrt(sim[e[0]][e[0]] * sim[e[1]][e[1]])\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def rwr_index(sub, c = 0.5):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    sim = np.linalg.pinv(dma - mat)\n",
    "    ide = np.identity(len(mat))\n",
    "    pmt = np.identity(len(mat))\n",
    "    es = []\n",
    "    for a in i.nodes():\n",
    "        e = np.zeros(len(mat))\n",
    "        e[a] = 1\n",
    "        es.append(e)\n",
    "        for b in i.nodes():\n",
    "            try:\n",
    "                nx.shortest_path_length(i, source = a, target = b)\n",
    "            except:\n",
    "                pmt[a][b] = 0\n",
    "            else:\n",
    "                if nx.degree(i, a) != 0:\n",
    "                    pmt[a][b] = 1/float(nx.degree(i, a))\n",
    "                else:\n",
    "                    pmt[a][b] = 0\n",
    "    es = np.array(es)\n",
    "    qs = []\n",
    "    for a in i.nodes():\n",
    "        if np.linalg.det(ide - c*np.transpose(pmt)) != 0:\n",
    "            q = ((1 - c)*np.linalg.inv(ide - c*np.transpose(pmt))).dot(es[a])\n",
    "        else:\n",
    "            q = es[a]\n",
    "        qs.append(q)\n",
    "    qs = np.array(qs)\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = qs[e[0]][e[1]] + qs[e[1]][e[0]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def matrix_forest_index(sub, alpha = 1):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    ide = np.identity(len(mat))\n",
    "    sim = np.linalg.inv(ide + alpha*(dma - mat))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def predict_nodes(G, nfolds = 10):\n",
    "    df = pd.DataFrame()\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    es = nx.non_edges(subs[0])\n",
    "    edges = []\n",
    "    y = {}\n",
    "    for e in es:\n",
    "        edges.append(e)\n",
    "        check = 0\n",
    "        if e in folds[0]:\n",
    "            check = 1\n",
    "        y[e] = check\n",
    "    df['Edges'] = edges\n",
    "    df['y'] = df['Edges'].map(y.get)\n",
    "    df['CN'] = df['Edges'].map(common_neighbours(subs[0]).get)\n",
    "    df['SaI'] = df['Edges'].map(salton_index(subs[0]).get)\n",
    "    df['JI'] = df['Edges'].map(jaccard_index(subs[0]).get)\n",
    "    df['SoI'] = df['Edges'].map(sorensen_index(subs[0]).get)\n",
    "    df['HPI'] = df['Edges'].map(hub_promoted_index(subs[0]).get)\n",
    "    df['HDI'] = df['Edges'].map(hub_depressed_index(subs[0]).get)\n",
    "    df['LHN1'] = df['Edges'].map(LHN1_index(subs[0]).get)\n",
    "    df['PAI'] = df['Edges'].map(preferential_attachment_index(subs[0]).get)\n",
    "    df['AAI'] = df['Edges'].map(adamic_adar_index(subs[0]).get)\n",
    "    df['RAI'] = df['Edges'].map(resource_allocation_index(subs[0]).get)\n",
    "    df['KzI'] = df['Edges'].map(katz_index(subs[0]).get)\n",
    "    df['LHN2'] = df['Edges'].map(lhn2_index(subs[0]).get)\n",
    "    df['ACT'] = df['Edges'].map(act_index(subs[0]).get)\n",
    "    df['CBL'] = df['Edges'].map(cbl_index(subs[0]).get)\n",
    "    df['RWR'] = df['Edges'].map(rwr_index(subs[0]).get)\n",
    "    df['MFI'] = df['Edges'].map(matrix_forest_index(subs[0]).get)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:122: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:136: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "df = predict_nodes(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(df[list(set(df.columns) - set(['y', 'Edges']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "y = np.array(df['y'])\n",
    "X = np.array(df[list(set(df.columns) - set(['y', 'Edges']))])\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99592668024439923"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9837067209775967"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - float(sum(y))/float(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_score(G, alg = 'rf'):\n",
    "    df = predict_other_nodes(G)\n",
    "    df = df.fillna(0)\n",
    "    y = np.array(df['y'])\n",
    "    X = np.array(df[list(set(df.columns) - set(['y', 'Edges']))])\n",
    "    if alg == 'rf':\n",
    "        rf = ensemble.RandomForestClassifier(class_weight = 'auto')\n",
    "        rf.fit(X, y)\n",
    "        print classification_report(y, rf.predict(X))\n",
    "    elif alg == 'log':\n",
    "        lf = linear_model.LogisticRegression(class_weight = 'auto')\n",
    "        lf.fit(X, y)\n",
    "        print classification_report(y, lf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5791\n",
      "          1       0.97      0.77      0.86        43\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_score(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1732\n",
      "          1       0.76      0.81      0.79        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_score(fixed_newman_dolphins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     41808\n",
      "          1       0.99      0.71      0.83       215\n",
      "\n",
      "avg / total       1.00      1.00      1.00     42023\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:122: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "calculate_score(fixed_newman_celegansneural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       483\n",
      "          1       0.88      0.88      0.88         8\n",
      "\n",
      "avg / total       1.00      1.00      1.00       491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:122: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:140: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "calculate_score(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     52820\n",
      "          1       0.95      0.89      0.92       213\n",
      "\n",
      "avg / total       1.00      1.00      1.00     53033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:122: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "pajek_us_air = nx.read_pajek('./netws/pajekds/USAir97.net')\n",
    "fixed_pajek_us_air = nx.Graph(nx.convert_node_labels_to_integers(pajek_us_air, first_label = 0))\n",
    "calculate_score(fixed_pajek_us_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92     41808\n",
      "          1       0.03      0.74      0.05       215\n",
      "\n",
      "avg / total       0.99      0.86      0.92     42023\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:122: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "calculate_score(fixed_newman_celegansneural, alg = 'log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def common_neighbours2(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = mat[e[0]][e[1]]\n",
    "    for e in i.edges():\n",
    "        edgesWithScore[e] = mat[e[0]][e[1]]\n",
    "    return edgesWithScore \n",
    "\n",
    "def salton_index2(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(np.sqrt(j * k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    for e in i.edges():\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(np.sqrt(j * k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def jaccard_index2(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        if nx.degree(i, e[0]) != 0 or nx.degree(i, e[1]) != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(len(set(i[e[0]])|set(i[e[1]])))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    for e in i.edges():\n",
    "        if nx.degree(i, e[0]) != 0 or nx.degree(i, e[1]) != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(len(set(i[e[0]])|set(i[e[1]])))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def sorensen_index2(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 or k != 0:\n",
    "            edgesWithScore[e] = 2*float(mat[e[0]][e[1]])/float(j + k)\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    for e in i.edges():\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 or k != 0:\n",
    "            edgesWithScore[e] = 2*float(mat[e[0]][e[1]])/float(j + k)\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def hub_promoted_index2(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(min(j, k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    for e in i.edges():\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(min(j, k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def hub_depressed_index2(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 or k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(max(j, k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    for e in i.edges():\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 or k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(max(j, k))\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def LHN1_index2(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1).dot(np.array((nx.to_numpy_matrix(i) != 0) * 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(j * k)\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    for e in i.edges():\n",
    "        j = nx.degree(i, e[0])\n",
    "        k = nx.degree(i, e[1])\n",
    "        if j != 0 and k != 0:\n",
    "            edgesWithScore[e] = float(mat[e[0]][e[1]])/float(j * k)\n",
    "        else:\n",
    "            edgesWithScore[e] = 0\n",
    "    return edgesWithScore\n",
    "\n",
    "def preferential_attachment_index2(sub):\n",
    "    i = sub\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = nx.degree(i, e[0]) * nx.degree(i, e[1])\n",
    "    for e in i.edges():\n",
    "        edgesWithScore[e] = nx.degree(i, e[0]) * nx.degree(i, e[1])\n",
    "    return edgesWithScore\n",
    "\n",
    "def adamic_adar_index2(sub):\n",
    "    i = sub\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = np.sum(1/np.log(nx.degree(i, sorted(nx.common_neighbors(i, e[0], e[1]))).values()))\n",
    "    for e in i.edges():\n",
    "        edgesWithScore[e] = np.sum(1/np.log(nx.degree(i, sorted(nx.common_neighbors(i, e[0], e[1]))).values()))\n",
    "    return edgesWithScore\n",
    "\n",
    "def resource_allocation_index2(sub):\n",
    "    i = sub\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = np.sum(1/np.array(\n",
    "                nx.degree(i, sorted(nx.common_neighbors(i, e[0], e[1]))).values()).astype(float))\n",
    "    for e in i.edges():\n",
    "        edgesWithScore[e] = np.sum(1/np.array(\n",
    "                nx.degree(i, sorted(nx.common_neighbors(i, e[0], e[1]))).values()).astype(float))\n",
    "    return edgesWithScore\n",
    "\n",
    "def katz_index2(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    ide = np.identity(len(mat))\n",
    "    beta = (1/float(max(np.linalg.eig(mat)[0])))/2\n",
    "    sim = np.linalg.inv(ide - beta*mat) - ide\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    for e in i.edges():\n",
    "        edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def lhn2_index2(sub, phi = 0.1):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    ide = np.identity(len(mat))\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = 0\n",
    "    if np.linalg.det(dma) != 0:\n",
    "        lambd = float(max(np.linalg.eig(mat)[0]))\n",
    "        sim = (2 * i.number_of_edges() * lambd * np.linalg.inv(dma)).dot(np.linalg.inv(\n",
    "        ide - (phi/lambd) * mat)).dot(np.linalg.inv(dma))\n",
    "        edges = nx.non_edges(i)\n",
    "        for e in edges:\n",
    "            edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "        for e in i.edges():\n",
    "            edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def act_index2(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    sim = np.linalg.pinv(dma - mat)\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = 1/float(sim[e[0]][e[0]] + sim[e[1]][e[1]] - 2*sim[e[0]][e[1]])\n",
    "    for e in i.edges():\n",
    "        edgesWithScore[e] = 1/float(sim[e[0]][e[0]] + sim[e[1]][e[1]] - 2*sim[e[0]][e[1]])\n",
    "    return edgesWithScore\n",
    "\n",
    "def cbl_index2(sub):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    sim = np.linalg.pinv(dma - mat)\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = float(sim[e[0]][e[1]])/np.sqrt(sim[e[0]][e[0]] * sim[e[1]][e[1]])\n",
    "    for e in i.edges():\n",
    "        edgesWithScore[e] = float(sim[e[0]][e[1]])/np.sqrt(sim[e[0]][e[0]] * sim[e[1]][e[1]])\n",
    "    return edgesWithScore\n",
    "\n",
    "def rwr_index2(sub, c = 0.5):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    sim = np.linalg.pinv(dma - mat)\n",
    "    ide = np.identity(len(mat))\n",
    "    pmt = np.identity(len(mat))\n",
    "    es = []\n",
    "    for a in i.nodes():\n",
    "        e = np.zeros(len(mat))\n",
    "        e[a] = 1\n",
    "        es.append(e)\n",
    "        for b in i.nodes():\n",
    "            try:\n",
    "                nx.shortest_path_length(i, source = a, target = b)\n",
    "            except:\n",
    "                pmt[a][b] = 0\n",
    "            else:\n",
    "                if nx.degree(i, a) != 0:\n",
    "                    pmt[a][b] = 1/float(nx.degree(i, a))\n",
    "                else:\n",
    "                    pmt[a][b] = 0\n",
    "    es = np.array(es)\n",
    "    qs = []\n",
    "    for a in i.nodes():\n",
    "        if np.linalg.det(ide - c*np.transpose(pmt)) != 0:\n",
    "            q = ((1 - c)*np.linalg.inv(ide - c*np.transpose(pmt))).dot(es[a])\n",
    "        else:\n",
    "            q = es[a]\n",
    "        qs.append(q)\n",
    "    qs = np.array(qs)\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = qs[e[0]][e[1]] + qs[e[1]][e[0]]\n",
    "    for e in i.edges():\n",
    "        edgesWithScore[e] = qs[e[0]][e[1]] + qs[e[1]][e[0]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def matrix_forest_index2(sub, alpha = 1):\n",
    "    i = sub\n",
    "    mat = np.array((nx.to_numpy_matrix(i) != 0) * 1.)\n",
    "    dma = np.diagflat(mat.sum(axis = 1))\n",
    "    ide = np.identity(len(mat))\n",
    "    sim = np.linalg.inv(ide + alpha*(dma - mat))\n",
    "    edgesWithScore = {}\n",
    "    edges = nx.non_edges(i)\n",
    "    for e in edges:\n",
    "        edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    for e in i.edges():\n",
    "        edgesWithScore[e] = sim[e[0]][e[1]]\n",
    "    return edgesWithScore\n",
    "\n",
    "def predict_other_nodes(G, nfolds = 10):\n",
    "    df = pd.DataFrame()\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "    es = nx.non_edges(subs[0])\n",
    "    edges = []\n",
    "    y = {}\n",
    "    for e in es:\n",
    "        edges.append(e)\n",
    "        #check = 0\n",
    "        #if e in folds[0]:\n",
    "        #    check = 1\n",
    "        #y[e] = check\n",
    "        y[e] = 0\n",
    "    for e in subs[0].edges():\n",
    "        edges.append(e)\n",
    "        y[e] = 1\n",
    "    df['Edges'] = edges\n",
    "    df['y'] = df['Edges'].map(y.get)\n",
    "    df['CN'] = df['Edges'].map(common_neighbours2(subs[0]).get)\n",
    "    df['SaI'] = df['Edges'].map(salton_index2(subs[0]).get)\n",
    "    df['JI'] = df['Edges'].map(jaccard_index2(subs[0]).get)\n",
    "    df['SoI'] = df['Edges'].map(sorensen_index2(subs[0]).get)\n",
    "    df['HPI'] = df['Edges'].map(hub_promoted_index2(subs[0]).get)\n",
    "    df['HDI'] = df['Edges'].map(hub_depressed_index2(subs[0]).get)\n",
    "    df['LHN1'] = df['Edges'].map(LHN1_index2(subs[0]).get)\n",
    "    df['PAI'] = df['Edges'].map(preferential_attachment_index2(subs[0]).get)\n",
    "    df['AAI'] = df['Edges'].map(adamic_adar_index2(subs[0]).get)\n",
    "    df['RAI'] = df['Edges'].map(resource_allocation_index2(subs[0]).get)\n",
    "    df['KzI'] = df['Edges'].map(katz_index2(subs[0]).get)\n",
    "    df['LHN2'] = df['Edges'].map(lhn2_index2(subs[0]).get)\n",
    "    df['ACT'] = df['Edges'].map(act_index2(subs[0]).get)\n",
    "    df['CBL'] = df['Edges'].map(cbl_index2(subs[0]).get)\n",
    "    df['RWR'] = df['Edges'].map(rwr_index2(subs[0]).get)\n",
    "    df['MFI'] = df['Edges'].map(matrix_forest_index2(subs[0]).get)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:170: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:190: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "df = predict_other_nodes(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       491\n",
      "          1       1.00      1.00      1.00        70\n",
      "\n",
      "avg / total       1.00      1.00      1.00       561\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:170: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:190: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "calculate_score(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = predict_other_nodes(nx.karate_club_graph())\n",
    "df = df.fillna(0)\n",
    "y = np.array(df['y'])\n",
    "X = np.array(df[list(set(df.columns) - set(['y', 'Edges']))])\n",
    "cw = {0: 1000, 1: 1}\n",
    "rf = ensemble.RandomForestClassifier(class_weight = 'auto')\n",
    "lf = linear_model.LogisticRegression(class_weight = 'auto')\n",
    "scf = svm.SVC(class_weight = 'auto', kernel = 'poly')\n",
    "knn = KNeighborsClassifier()\n",
    "lf.fit(X, y)\n",
    "knn.fit(X, y)\n",
    "scf.fit(X, y)\n",
    "print classification_report(y, scf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunks = [i for i in chunk(df['Edges'], 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dats = []\n",
    "for i in chunks:\n",
    "    d = df[[(j in i) for j in df['Edges']]]\n",
    "    dats.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in dats:\n",
    "    dat = pd.concat([d, df[df['y'] == 1]])\n",
    "    y_train = np.array(dat['y'])\n",
    "    X_train = np.array(dat[list(set(dat.columns) - set(['y', 'Edges']))])\n",
    "    y_test = np.array(df['y'])\n",
    "    X_test = np.array(df[list(set(df.columns) - set(['y', 'Edges']))])\n",
    "    scf = svm.SVC(class_weight = 'auto', kernel = 'poly')\n",
    "    scf.fit(X_train, y_train)\n",
    "    print df[scf.predict(X_test) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_folds_inds(G, nfolds = 10):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    subs = []\n",
    "    frames = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        subs.append(graph.copy())\n",
    "        df = pd.DataFrame()\n",
    "        es = nx.non_edges(subs[i])\n",
    "        edges = []\n",
    "        y = {}\n",
    "        for e in es:\n",
    "            edges.append(e)\n",
    "            if e in folds[i]:\n",
    "                y[e] = 1\n",
    "            else:\n",
    "                y[e] = 0\n",
    "        df['Edges'] = edges\n",
    "        df['y'] = df['Edges'].map(y.get)\n",
    "        df['CN'] = df['Edges'].map(common_neighbours(subs[i]).get)\n",
    "        df['SaI'] = df['Edges'].map(salton_index(subs[i]).get)\n",
    "        df['JI'] = df['Edges'].map(jaccard_index(subs[i]).get)\n",
    "        df['SoI'] = df['Edges'].map(sorensen_index(subs[i]).get)\n",
    "        df['HPI'] = df['Edges'].map(hub_promoted_index(subs[i]).get)\n",
    "        df['HDI'] = df['Edges'].map(hub_depressed_index(subs[i]).get)\n",
    "        df['LHN1'] = df['Edges'].map(LHN1_index(subs[i]).get)\n",
    "        df['PAI'] = df['Edges'].map(preferential_attachment_index(subs[i]).get)\n",
    "        df['AAI'] = df['Edges'].map(adamic_adar_index(subs[i]).get)\n",
    "        df['RAI'] = df['Edges'].map(resource_allocation_index(subs[i]).get)\n",
    "        df['KzI'] = df['Edges'].map(katz_index(subs[i]).get)\n",
    "        df['LHN2'] = df['Edges'].map(lhn2_index(subs[i]).get)\n",
    "        df['ACT'] = df['Edges'].map(act_index(subs[i]).get)\n",
    "        df['CBL'] = df['Edges'].map(cbl_index(subs[i]).get)\n",
    "        df['RWR'] = df['Edges'].map(rwr_index(subs[i]).get)\n",
    "        df['MFI'] = df['Edges'].map(matrix_forest_index(subs[i]).get)\n",
    "        df = df.fillna(0)\n",
    "        frames.append(df)\n",
    "    return frames, folds, subs\n",
    "\n",
    "def print_accs(G):\n",
    "    frames, folds, subs = get_folds_inds(G)\n",
    "    prc = []\n",
    "    prt = ((G.number_of_nodes()*(G.number_of_nodes() - 1))/2)/(G.number_of_edges())\n",
    "    rc = []\n",
    "    for f in xrange(len(frames)):\n",
    "        eds = []\n",
    "        chunks = [i for i in chunk(frames[f]['Edges'], 10)]\n",
    "        dats = []\n",
    "        for i in chunks:\n",
    "            d = frames[f][[(j in i) for j in frames[f]['Edges']]]\n",
    "            dats.append(d)\n",
    "        for d in dats:\n",
    "            dat = pd.concat([d, frames[f][frames[f]['y'] == 1]])\n",
    "            y_train = np.array(dat['y'])\n",
    "            X_train = np.array(dat[list(set(dat.columns) - set(['y', 'Edges']))])\n",
    "            y_test = np.array(frames[f]['y'])\n",
    "            X_test = np.array(frames[f][list(set(frames[f].columns) - set(['y', 'Edges']))])\n",
    "            scf = svm.SVC(class_weight = 'auto', kernel = 'poly')\n",
    "            scf.fit(X_train, y_train)\n",
    "            tr = [(i in G.edges()) for i in frames[f][scf.predict(X_test) == 1]['Edges']]\n",
    "            #a1 = np.sum([rf.predict(X_test) == 1])\n",
    "            #how_many_from_G = np.sum([(i in G.edges()) for i in frames[f][rf.predict(X_test) == 1]['Edges']])\n",
    "            #how_many_new = np.sum([(i in folds[f]) for i in frames[f][rf.predict(X_test) == 1]['Edges']])\n",
    "            #how_many_bad = np.sum([(i not in G.edges()) for i in frames[f][rf.predict(X_test) == 1]['Edges']])\n",
    "            #print a1, how_many_from_G, how_many_new, how_many_bad, float(np.sum(tr))/float(len(tr))\n",
    "            for e in frames[f][scf.predict(X_test) == 1]['Edges']:\n",
    "                if e not in eds:\n",
    "                    eds.append(e)\n",
    "        tp = np.sum([(i in folds[f]) for i in eds])\n",
    "        fp = np.sum([(i not in G.edges()) for i in eds])\n",
    "        fn = np.sum([(i not in eds) for i in folds[f]])\n",
    "        if tp + fp != 0:\n",
    "            print 'precision =', float(tp)/float(tp + fp)\n",
    "            prc.append(float(tp)/float(tp + fp))\n",
    "        else:\n",
    "            print 'precision =', 0\n",
    "            prc.append(0)\n",
    "        if tp + fn != 0:\n",
    "            print 'recall =', float(tp)/float(tp + fn)\n",
    "            rc.append(float(tp)/float(tp + fn))\n",
    "        else:\n",
    "            print 'recall =', 0\n",
    "            rc.append(0)\n",
    "        print ''\n",
    "    print 'mean precision =', np.mean(prc), 'mean recall =', np.mean(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.0419161676647\n",
      "recall = 0.875\n",
      "\n",
      "precision = 0.0729166666667\n",
      "recall = 0.875\n",
      "\n",
      "precision = 0.0721649484536\n",
      "recall = 0.875\n",
      "\n",
      "precision = 0.041958041958\n",
      "recall = 0.75\n",
      "\n",
      "precision = 0.028\n",
      "recall = 0.875\n",
      "\n",
      "precision = 0.0414201183432\n",
      "recall = 0.875\n",
      "\n",
      "precision = 0.122807017544\n",
      "recall = 0.875\n",
      "\n",
      "precision = 0.0677966101695\n",
      "recall = 1.0\n",
      "\n",
      "precision = 0.0429447852761\n",
      "recall = 1.0\n",
      "\n",
      "precision = 0.0754716981132\n",
      "recall = 0.571428571429\n",
      "\n",
      "mean precision = 0.0607396054189 mean recall = 0.857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:139: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "print_accs(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###New ideas for supervised learning:\n",
    "1. Do 10-fold check: $G' = G - G^{*}$ where $G$ - edges in $G$, $G^{*}$ - 10% removed.\n",
    "2. Take $G'$ and do 10-fold on them:\n",
    " - Remove 10%, then take complement to complete graph and run indices on them.\n",
    " - Do that 10 times for all folds.\n",
    " - Compile dataset of all metrics of edges from $G'$ and means of all indices of edges in complement between all folds.\n",
    " - Train classifier on that dataset\n",
    "3. Take $G'$ as complete and calculate indices on the complement of $G'$.\n",
    "4. Run classifier on the dataset as test set.\n",
    "5. Calculate precision of how many edges from $G^{*}$ were classified correctly.\n",
    "6. ??????\n",
    "7. PROFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_10_fold_on_G(G, nfolds = 10):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    frames = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        sub = graph.copy()\n",
    "        df = pd.DataFrame()\n",
    "        es = nx.non_edges(sub)\n",
    "        edges = []\n",
    "        y = {}\n",
    "        for e in es:\n",
    "            edges.append(e)\n",
    "            if e in folds[i]:\n",
    "                y[e] = 1\n",
    "            else:\n",
    "                y[e] = 0\n",
    "        df['Edges'] = edges\n",
    "        df['y'] = df['Edges'].map(y.get)\n",
    "        df['CN'] = df['Edges'].map(common_neighbours(sub).get)\n",
    "        df['SaI'] = df['Edges'].map(salton_index(sub).get)\n",
    "        df['JI'] = df['Edges'].map(jaccard_index(sub).get)\n",
    "        df['SoI'] = df['Edges'].map(sorensen_index(sub).get)\n",
    "        df['HPI'] = df['Edges'].map(hub_promoted_index(sub).get)\n",
    "        df['HDI'] = df['Edges'].map(hub_depressed_index(sub).get)\n",
    "        df['LHN1'] = df['Edges'].map(LHN1_index(sub).get)\n",
    "        df['PAI'] = df['Edges'].map(preferential_attachment_index(sub).get)\n",
    "        df['AAI'] = df['Edges'].map(adamic_adar_index(sub).get)\n",
    "        df['RAI'] = df['Edges'].map(resource_allocation_index(sub).get)\n",
    "        df['KzI'] = df['Edges'].map(katz_index(sub).get)\n",
    "        df['LHN2'] = df['Edges'].map(lhn2_index(sub).get)\n",
    "        df['ACT'] = df['Edges'].map(act_index(sub).get)\n",
    "        df['CBL'] = df['Edges'].map(cbl_index(sub).get)\n",
    "        df['RWR'] = df['Edges'].map(rwr_index(sub).get)\n",
    "        df['MFI'] = df['Edges'].map(matrix_forest_index(sub).get)\n",
    "        df = df.fillna(0)\n",
    "        frames.append(df)\n",
    "    return frames, folds\n",
    "\n",
    "def run_indices_on_compl(sub):\n",
    "    df = pd.DataFrame()\n",
    "    es = nx.non_edges(sub)\n",
    "    edges = []\n",
    "    for e in es:\n",
    "        edges.append(e)\n",
    "    df['Edges'] = edges\n",
    "    df['CN'] = df['Edges'].map(common_neighbours(sub).get)\n",
    "    df['SaI'] = df['Edges'].map(salton_index(sub).get)\n",
    "    df['JI'] = df['Edges'].map(jaccard_index(sub).get)\n",
    "    df['SoI'] = df['Edges'].map(sorensen_index(sub).get)\n",
    "    df['HPI'] = df['Edges'].map(hub_promoted_index(sub).get)\n",
    "    df['HDI'] = df['Edges'].map(hub_depressed_index(sub).get)\n",
    "    df['LHN1'] = df['Edges'].map(LHN1_index(sub).get)\n",
    "    df['PAI'] = df['Edges'].map(preferential_attachment_index(sub).get)\n",
    "    df['AAI'] = df['Edges'].map(adamic_adar_index(sub).get)\n",
    "    df['RAI'] = df['Edges'].map(resource_allocation_index(sub).get)\n",
    "    df['KzI'] = df['Edges'].map(katz_index(sub).get)\n",
    "    df['LHN2'] = df['Edges'].map(lhn2_index(sub).get)\n",
    "    df['ACT'] = df['Edges'].map(act_index(sub).get)\n",
    "    df['CBL'] = df['Edges'].map(cbl_index(sub).get)\n",
    "    df['RWR'] = df['Edges'].map(rwr_index(sub).get)\n",
    "    df['MFI'] = df['Edges'].map(matrix_forest_index(sub).get)\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def get_G_dash(G, nfolds = 10):\n",
    "    f1s = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    rocaucs = []\n",
    "    accuracies = []\n",
    "    avg_prcs = []\n",
    "    random.seed(0)\n",
    "    fs = [i for i in chunk(G.edges(), nfolds)]\n",
    "    # so subs are G' x 10\n",
    "    # folds are G*\n",
    "    for j in xrange(nfolds):\n",
    "        complete_dataset = pd.DataFrame()\n",
    "        graph = G.copy()\n",
    "        for c in fs[j]:\n",
    "            graph.remove_edge(*c)\n",
    "        sub = graph.copy()\n",
    "        frames, folds = run_10_fold_on_G(sub)\n",
    "        complete_dataset = pd.concat([(i[i['y'] == 1]) for i in frames])\n",
    "        #print 'complete_dataset_before'\n",
    "        #print complete_dataset\n",
    "        zeros = pd.concat([(i[i['y'] == 0]) for i in frames])\n",
    "        zeros.index = zeros['Edges']\n",
    "        zeros = zeros.groupby(zeros.index).mean()\n",
    "        complete_dataset = pd.concat([complete_dataset, zeros])\n",
    "        #print 'complete_dataset_after:'\n",
    "        #print complete_dataset\n",
    "        complete_dataset.replace([np.inf, -np.inf], np.nan)\n",
    "        complete_dataset = complete_dataset.fillna(0)\n",
    "        y_train = np.array(complete_dataset['y'])\n",
    "        X_train = np.nan_to_num(\n",
    "            np.array(complete_dataset[list(set(complete_dataset.columns) - set(['y', 'Edges']))]).astype('float32'))\n",
    "        rf = ensemble.RandomForestClassifier(class_weight = 'auto')\n",
    "        rf.fit(X_train, y_train)\n",
    "        #print 'cr on train:'\n",
    "        #print classification_report(y_train, rf.predict(X_train))\n",
    "        test_set = run_indices_on_compl(sub)\n",
    "        X_test = np.array(test_set[list(set(test_set.columns) - set(['Edges']))])\n",
    "        y_test = np.array([(i in fs[j]) for i in test_set['Edges']])*1\n",
    "        print 'cr on test for fold', j+1\n",
    "        y_pred = rf.predict(X_test)\n",
    "        print classification_report(y_test, y_pred)\n",
    "        f1s.append(metrics.f1_score(y_test, y_pred))\n",
    "        precisions.append(metrics.precision_score(y_test, y_pred))\n",
    "        recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        rocaucs.append(metrics.roc_auc_score(y_test, y_pred))\n",
    "        accuracies.append(metrics.accuracy_score(y_test, y_pred))\n",
    "        avg_prcs.append(metrics.average_precision_score(y_test, y_pred))\n",
    "    print 'mean infos:'\n",
    "    print 'mean F1:', np.mean(f1s)\n",
    "    print 'mean precision:', np.mean(precisions)\n",
    "    print 'mean recall:', np.mean(recalls)\n",
    "    print 'mean roc_auc:', np.mean(rocaucs)\n",
    "    print 'mean accuracy:', np.mean(accuracies)\n",
    "    print 'mean avg_precision:', np.mean(avg_prcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:139: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr on test for fold 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.29      0.45       483\n",
      "          1       0.02      0.88      0.04         8\n",
      "\n",
      "avg / total       0.98      0.30      0.44       491\n",
      "\n",
      "cr on test for fold 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.97      0.98       483\n",
      "          1       0.06      0.12      0.08         8\n",
      "\n",
      "avg / total       0.97      0.96      0.96       491\n",
      "\n",
      "cr on test for fold 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.77      0.87       483\n",
      "          1       0.04      0.50      0.07         8\n",
      "\n",
      "avg / total       0.97      0.77      0.86       491\n",
      "\n",
      "cr on test for fold 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.47      0.63       483\n",
      "          1       0.02      0.62      0.04         8\n",
      "\n",
      "avg / total       0.97      0.47      0.62       491\n",
      "\n",
      "cr on test for fold 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.86      0.92       483\n",
      "          1       0.01      0.12      0.03         8\n",
      "\n",
      "avg / total       0.97      0.85      0.90       491\n",
      "\n",
      "cr on test for fold 6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.16      0.27       483\n",
      "          1       0.01      0.38      0.01         8\n",
      "\n",
      "avg / total       0.92      0.16      0.27       491\n",
      "\n",
      "cr on test for fold 7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.65      0.79       483\n",
      "          1       0.04      0.88      0.08         8\n",
      "\n",
      "avg / total       0.98      0.65      0.78       491\n",
      "\n",
      "cr on test for fold 8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.23      0.37       483\n",
      "          1       0.01      0.50      0.02         8\n",
      "\n",
      "avg / total       0.95      0.24      0.37       491\n",
      "\n",
      "cr on test for fold 9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.67      0.80       483\n",
      "          1       0.02      0.43      0.04         7\n",
      "\n",
      "avg / total       0.97      0.67      0.79       490\n",
      "\n",
      "cr on test for fold 10\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.32      0.48       483\n",
      "          1       0.01      0.57      0.02         7\n",
      "\n",
      "avg / total       0.97      0.32      0.48       490\n",
      "\n",
      "mean infos:\n",
      "mean F1: 0.0423121895719\n",
      "mean precision: 0.0240464866693\n",
      "mean recall: 0.5\n",
      "mean roc_auc: 0.520082815735\n",
      "mean accuracy: 0.53951037034\n",
      "mean avg_precision: 0.265996184853\n"
     ]
    }
   ],
   "source": [
    "get_G_dash(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr on test for fold 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.73      0.84      5791\n",
      "          1       0.01      0.30      0.02        43\n",
      "\n",
      "avg / total       0.99      0.73      0.84      5834\n",
      "\n",
      "cr on test for fold 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.69      0.81      5791\n",
      "          1       0.01      0.47      0.02        43\n",
      "\n",
      "avg / total       0.99      0.69      0.81      5834\n",
      "\n",
      "cr on test for fold"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:139: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.66      0.79      5791\n",
      "          1       0.01      0.42      0.02        43\n",
      "\n",
      "avg / total       0.99      0.66      0.79      5834\n",
      "\n",
      "cr on test for fold 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.10      0.18      5791\n",
      "          1       0.01      1.00      0.02        43\n",
      "\n",
      "avg / total       0.99      0.11      0.18      5834\n",
      "\n",
      "cr on test for fold 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.69      0.81      5791\n",
      "          1       0.01      0.35      0.02        43\n",
      "\n",
      "avg / total       0.99      0.68      0.81      5834\n",
      "\n",
      "cr on test for fold 6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.07      0.13      5791\n",
      "          1       0.01      0.98      0.01        42\n",
      "\n",
      "avg / total       0.99      0.08      0.13      5833\n",
      "\n",
      "cr on test for fold 7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.67      0.80      5791\n",
      "          1       0.01      0.38      0.02        42\n",
      "\n",
      "avg / total       0.99      0.67      0.80      5833\n",
      "\n",
      "cr on test for fold 8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.72      0.84      5791\n",
      "          1       0.01      0.29      0.01        42\n",
      "\n",
      "avg / total       0.99      0.72      0.83      5833\n",
      "\n",
      "cr on test for fold 9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.67      0.80      5791\n",
      "          1       0.01      0.36      0.02        42\n",
      "\n",
      "avg / total       0.99      0.67      0.79      5833\n",
      "\n",
      "cr on test for fold 10\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.70      0.82      5791\n",
      "          1       0.01      0.36      0.02        42\n",
      "\n",
      "avg / total       0.99      0.69      0.81      5833\n",
      "\n",
      "mean infos:\n",
      "mean F1: 0.0165057741214\n",
      "mean precision: 0.00842341860435\n",
      "mean recall: 0.489202657807\n",
      "mean roc_auc: 0.529388066945\n",
      "mean accuracy: 0.568989126623\n",
      "mean avg_precision: 0.250672988751\n"
     ]
    }
   ],
   "source": [
    "newman_adjnoun = nx.read_gml('./netws/newman/adjnoun/adjnoun.gml')\n",
    "get_G_dash(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr on test for fold 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.81      0.89      1732\n",
      "          1       0.02      0.38      0.03        16\n",
      "\n",
      "avg / total       0.98      0.80      0.88      1748\n",
      "\n",
      "cr on test for fold 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.85      0.92      1732\n",
      "          1       0.02      0.25      0.03        16\n",
      "\n",
      "avg / total       0.98      0.85      0.91      1748\n",
      "\n",
      "cr on test for fold 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.86      0.92      1732\n",
      "          1       0.02      0.31      0.04        16\n",
      "\n",
      "avg / total       0.98      0.86      0.91      1748\n",
      "\n",
      "cr on test for fold"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:139: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.86      0.92      1732\n",
      "          1       0.03      0.44      0.05        16\n",
      "\n",
      "avg / total       0.99      0.86      0.92      1748\n",
      "\n",
      "cr on test for fold 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.42      0.59      1732\n",
      "          1       0.01      0.69      0.02        16\n",
      "\n",
      "avg / total       0.98      0.43      0.59      1748\n",
      "\n",
      "cr on test for fold 6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.79      0.88      1732\n",
      "          1       0.02      0.38      0.03        16\n",
      "\n",
      "avg / total       0.98      0.79      0.87      1748\n",
      "\n",
      "cr on test for fold 7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.54      0.70      1732\n",
      "          1       0.02      0.88      0.03        16\n",
      "\n",
      "avg / total       0.99      0.54      0.70      1748\n",
      "\n",
      "cr on test for fold 8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.82      0.90      1732\n",
      "          1       0.02      0.38      0.04        16\n",
      "\n",
      "avg / total       0.98      0.82      0.89      1748\n",
      "\n",
      "cr on test for fold 9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.61      0.75      1732\n",
      "          1       0.01      0.38      0.02        16\n",
      "\n",
      "avg / total       0.98      0.60      0.75      1748\n",
      "\n",
      "cr on test for fold 10\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.55      0.71      1732\n",
      "          1       0.01      0.40      0.02        15\n",
      "\n",
      "avg / total       0.98      0.55      0.71      1747\n",
      "\n",
      "mean infos:\n",
      "mean F1: 0.0309263843896\n",
      "mean precision: 0.0161752809295\n",
      "mean recall: 0.44625\n",
      "mean roc_auc: 0.578985277136\n",
      "mean accuracy: 0.709299400476\n",
      "mean avg_precision: 0.233729950296\n"
     ]
    }
   ],
   "source": [
    "get_G_dash(fixed_newman_dolphins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr on test for fold 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88     52820\n",
      "          1       0.01      0.74      0.03       213\n",
      "\n",
      "avg / total       0.99      0.79      0.88     53033\n",
      "\n",
      "cr on test for fold 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87     52820\n",
      "          1       0.01      0.67      0.02       213\n",
      "\n",
      "avg / total       0.99      0.77      0.87     53033\n",
      "\n",
      "cr on test for fold 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.81      0.89     52820\n",
      "          1       0.02      0.85      0.03       213\n",
      "\n",
      "avg / total       1.00      0.81      0.89     53033\n",
      "\n",
      "cr on test for fold 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.87     52820\n",
      "          1       0.01      0.60      0.02       213\n",
      "\n",
      "avg / total       0.99      0.78      0.87     53033\n",
      "\n",
      "cr on test for fold 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86     52820\n",
      "          1       0.01      0.69      0.02       213\n",
      "\n",
      "avg / total       0.99      0.75      0.85     53033\n",
      "\n",
      "cr on test for fold 6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88     52820\n",
      "          1       0.01      0.31      0.01       213\n",
      "\n",
      "avg / total       0.99      0.79      0.88     53033\n",
      "\n",
      "cr on test for fold 7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86     52820\n",
      "          1       0.01      0.52      0.02       212\n",
      "\n",
      "avg / total       0.99      0.75      0.85     53032\n",
      "\n",
      "cr on test for fold 8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.73      0.84     52820\n",
      "          1       0.01      0.72      0.02       212\n",
      "\n",
      "avg / total       0.99      0.73      0.84     53032\n",
      "\n",
      "cr on test for fold 9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.79      0.88     52820\n",
      "          1       0.01      0.61      0.02       212\n",
      "\n",
      "avg / total       0.99      0.78      0.88     53032\n",
      "\n",
      "cr on test for fold 10\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.86     52820\n",
      "          1       0.01      0.56      0.02       212\n",
      "\n",
      "avg / total       0.99      0.76      0.86     53032\n",
      "\n",
      "mean infos:\n",
      "mean F1: 0.0217132265301\n",
      "mean precision: 0.0110499843663\n",
      "mean recall: 0.627422712375\n",
      "mean roc_auc: 0.699376823813\n",
      "mean accuracy: 0.770754093532\n",
      "mean avg_precision: 0.319983059244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "pajek_us_air = nx.read_pajek('./netws/pajekds/USAir97.net')\n",
    "fixed_pajek_us_air = nx.Graph(nx.convert_node_labels_to_integers(pajek_us_air, first_label = 0))\n",
    "get_G_dash(fixed_pajek_us_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_G_dash_svm_poly(G, nfolds = 10):\n",
    "    f1s = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    rocaucs = []\n",
    "    accuracies = []\n",
    "    avg_prcs = []\n",
    "    random.seed(0)\n",
    "    fs = [i for i in chunk(G.edges(), nfolds)]\n",
    "    # so subs are G' x 10\n",
    "    # folds are G*\n",
    "    for j in xrange(nfolds):\n",
    "        complete_dataset = pd.DataFrame()\n",
    "        graph = G.copy()\n",
    "        for c in fs[j]:\n",
    "            graph.remove_edge(*c)\n",
    "        sub = graph.copy()\n",
    "        frames, folds = run_10_fold_on_G(sub)\n",
    "        complete_dataset = pd.concat([(i[i['y'] == 1]) for i in frames])\n",
    "        #print 'complete_dataset_before'\n",
    "        #print complete_dataset\n",
    "        zeros = pd.concat([(i[i['y'] == 0]) for i in frames])\n",
    "        zeros.index = zeros['Edges']\n",
    "        zeros = zeros.groupby(zeros.index).mean()\n",
    "        complete_dataset = pd.concat([complete_dataset, zeros])\n",
    "        #print 'complete_dataset_after:'\n",
    "        #print complete_dataset\n",
    "        complete_dataset.replace([np.inf, -np.inf], np.nan)\n",
    "        complete_dataset = complete_dataset.fillna(0)\n",
    "        y_train = np.array(complete_dataset['y'])\n",
    "        X_train = np.nan_to_num(\n",
    "            np.array(complete_dataset[list(set(complete_dataset.columns) - set(['y', 'Edges']))]).astype('float32'))\n",
    "        rf = svm.SVC(kernel = 'poly', class_weight = 'auto')\n",
    "        rf.fit(X_train, y_train)\n",
    "        #print 'cr on train:'\n",
    "        #print classification_report(y_train, rf.predict(X_train))\n",
    "        test_set = run_indices_on_compl(sub)\n",
    "        X_test = np.array(test_set[list(set(test_set.columns) - set(['Edges']))])\n",
    "        y_test = np.array([(i in fs[j]) for i in test_set['Edges']])*1\n",
    "        print 'cr on test for fold', j+1\n",
    "        y_pred = rf.predict(X_test)\n",
    "        print classification_report(y_test, y_pred)\n",
    "        f1s.append(metrics.f1_score(y_test, y_pred))\n",
    "        precisions.append(metrics.precision_score(y_test, y_pred))\n",
    "        recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        rocaucs.append(metrics.roc_auc_score(y_test, y_pred))\n",
    "        accuracies.append(metrics.accuracy_score(y_test, y_pred))\n",
    "        avg_prcs.append(metrics.average_precision_score(y_test, y_pred))\n",
    "    print 'mean infos:'\n",
    "    print 'mean F1:', np.mean(f1s)\n",
    "    print 'mean precision:', np.mean(precisions)\n",
    "    print 'mean recall:', np.mean(recalls)\n",
    "    print 'mean roc_auc:', np.mean(rocaucs)\n",
    "    print 'mean accuracy:', np.mean(accuracies)\n",
    "    print 'mean avg_precision:', np.mean(avg_prcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/kernel/__main__.py:139: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr on test for fold 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.82      0.89       483\n",
      "          1       0.04      0.50      0.08         8\n",
      "\n",
      "avg / total       0.97      0.81      0.88       491\n",
      "\n",
      "cr on test for fold 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.93      0.96       483\n",
      "          1       0.08      0.38      0.13         8\n",
      "\n",
      "avg / total       0.97      0.92      0.94       491\n",
      "\n",
      "cr on test for fold 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.88      0.93       483\n",
      "          1       0.08      0.62      0.14         8\n",
      "\n",
      "avg / total       0.98      0.88      0.92       491\n",
      "\n",
      "cr on test for fold 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.78      0.87       483\n",
      "          1       0.04      0.62      0.08         8\n",
      "\n",
      "avg / total       0.98      0.77      0.86       491\n",
      "\n",
      "cr on test for fold 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.67      0.80       483\n",
      "          1       0.02      0.50      0.05         8\n",
      "\n",
      "avg / total       0.97      0.66      0.78       491\n",
      "\n",
      "cr on test for fold 6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.83      0.90       483\n",
      "          1       0.02      0.25      0.04         8\n",
      "\n",
      "avg / total       0.97      0.82      0.89       491\n",
      "\n",
      "cr on test for fold 7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.69      0.82       483\n",
      "          1       0.04      0.88      0.08         8\n",
      "\n",
      "avg / total       0.98      0.69      0.80       491\n",
      "\n",
      "cr on test for fold 8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.90      0.94       483\n",
      "          1       0.08      0.50      0.13         8\n",
      "\n",
      "avg / total       0.98      0.89      0.93       491\n",
      "\n",
      "cr on test for fold 9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.87       483\n",
      "          1       0.05      0.86      0.10         7\n",
      "\n",
      "avg / total       0.98      0.78      0.86       490\n",
      "\n",
      "cr on test for fold 10\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.66      0.79       483\n",
      "          1       0.02      0.57      0.05         7\n",
      "\n",
      "avg / total       0.98      0.66      0.78       490\n",
      "\n",
      "mean infos:\n",
      "mean F1: 0.0888180417602\n",
      "mean precision: 0.0493255406809\n",
      "mean recall: 0.567857142857\n",
      "mean roc_auc: 0.680098343685\n",
      "mean accuracy: 0.788683652687\n",
      "mean avg_precision: 0.312054494851\n"
     ]
    }
   ],
   "source": [
    "get_G_dash_svm_poly(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newman_adjnoun = nx.read_gml('./netws/newman/adjnoun/adjnoun.gml')\n",
    "get_G_dash_svm_poly(newman_adjnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newman_dolphins = nx.read_gml('./netws/newman/dolphins/dolphins.gml')\n",
    "fixed_newman_dolphins = nx.Graph(nx.convert_node_labels_to_integers(newman_dolphins, first_label = 0))\n",
    "get_G_dash_svm_poly(fixed_newman_dolphins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "def run_10_fold_on_G(G, nfolds = 10):\n",
    "    random.seed(0)\n",
    "    folds = [i for i in chunk(G.edges(), nfolds)]\n",
    "    frames = []\n",
    "    for i in xrange(nfolds):\n",
    "        graph = G.copy()\n",
    "        for c in folds[i]:\n",
    "            graph.remove_edge(*c)\n",
    "        sub = graph.copy()\n",
    "        df = pd.DataFrame()\n",
    "        es = nx.non_edges(sub)\n",
    "        edges = []\n",
    "        y = {}\n",
    "        for e in es:\n",
    "            edges.append(e)\n",
    "            if e in folds[i]:\n",
    "                y[e] = 1\n",
    "            else:\n",
    "                y[e] = 0\n",
    "        df['Edges'] = edges\n",
    "        df['y'] = df['Edges'].map(y.get)\n",
    "        df['CN'] = df['Edges'].map(common_neighbours(sub).get)\n",
    "        df['SaI'] = df['Edges'].map(salton_index(sub).get)\n",
    "        df['JI'] = df['Edges'].map(jaccard_index(sub).get)\n",
    "        df['SoI'] = df['Edges'].map(sorensen_index(sub).get)\n",
    "        df['HPI'] = df['Edges'].map(hub_promoted_index(sub).get)\n",
    "        df['HDI'] = df['Edges'].map(hub_depressed_index(sub).get)\n",
    "        df['LHN1'] = df['Edges'].map(LHN1_index(sub).get)\n",
    "        df['PAI'] = df['Edges'].map(preferential_attachment_index(sub).get)\n",
    "        df['AAI'] = df['Edges'].map(adamic_adar_index(sub).get)\n",
    "        df['RAI'] = df['Edges'].map(resource_allocation_index(sub).get)\n",
    "        df['KzI'] = df['Edges'].map(katz_index(sub).get)\n",
    "        df['LHN2'] = df['Edges'].map(lhn2_index(sub).get)\n",
    "        df['ACT'] = df['Edges'].map(act_index(sub).get)\n",
    "        df['CBL'] = df['Edges'].map(cbl_index(sub).get)\n",
    "        df['RWR'] = df['Edges'].map(rwr_index(sub).get)\n",
    "        df['MFI'] = df['Edges'].map(matrix_forest_index(sub).get)\n",
    "        df = df.fillna(0)\n",
    "        frames.append(df)\n",
    "    return frames, folds\n",
    "\n",
    "def run_indices_on_compl(sub):\n",
    "    df = pd.DataFrame()\n",
    "    es = nx.non_edges(sub)\n",
    "    edges = []\n",
    "    for e in es:\n",
    "        edges.append(e)\n",
    "    df['Edges'] = edges\n",
    "    df['CN'] = df['Edges'].map(common_neighbours(sub).get)\n",
    "    df['SaI'] = df['Edges'].map(salton_index(sub).get)\n",
    "    df['JI'] = df['Edges'].map(jaccard_index(sub).get)\n",
    "    df['SoI'] = df['Edges'].map(sorensen_index(sub).get)\n",
    "    df['HPI'] = df['Edges'].map(hub_promoted_index(sub).get)\n",
    "    df['HDI'] = df['Edges'].map(hub_depressed_index(sub).get)\n",
    "    df['LHN1'] = df['Edges'].map(LHN1_index(sub).get)\n",
    "    df['PAI'] = df['Edges'].map(preferential_attachment_index(sub).get)\n",
    "    df['AAI'] = df['Edges'].map(adamic_adar_index(sub).get)\n",
    "    df['RAI'] = df['Edges'].map(resource_allocation_index(sub).get)\n",
    "    df['KzI'] = df['Edges'].map(katz_index(sub).get)\n",
    "    df['LHN2'] = df['Edges'].map(lhn2_index(sub).get)\n",
    "    df['ACT'] = df['Edges'].map(act_index(sub).get)\n",
    "    df['CBL'] = df['Edges'].map(cbl_index(sub).get)\n",
    "    df['RWR'] = df['Edges'].map(rwr_index(sub).get)\n",
    "    df['MFI'] = df['Edges'].map(matrix_forest_index(sub).get)\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def get_folds_test(G, nfolds = 10):\n",
    "    f1s = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    rocaucs = []\n",
    "    accuracies = []\n",
    "    avg_prcs = []\n",
    "    random.seed(0)\n",
    "    frames, folds = run_10_fold_on_G(G)\n",
    "    for j in xrange(nfolds):\n",
    "        test_dataset = frames[j]\n",
    "        train_dataset = pd.concat(frames[:j] + frames[(j+1):])\n",
    "        y_train = np.array(train_dataset['y'])\n",
    "        X_train = np.nan_to_num(\n",
    "            np.array(train_dataset[list(set(train_dataset.columns) - set(['y', 'Edges']))]).astype('float32'))\n",
    "        rf = svm.SVC(kernel = 'poly', class_weight = 'auto')\n",
    "        rf.fit(X_train, y_train)\n",
    "        X_test = np.nan_to_num(\n",
    "            np.array(test_dataset[list(set(test_dataset.columns) - set(['y', 'Edges']))]).astype('float32'))\n",
    "        y_test = np.array(test_dataset['y'])\n",
    "        print 'cr on test for fold', j+1\n",
    "        y_pred = rf.predict(X_test)\n",
    "        print classification_report(y_test, y_pred)\n",
    "        f1s.append(metrics.f1_score(y_test, y_pred))\n",
    "        precisions.append(metrics.precision_score(y_test, y_pred))\n",
    "        recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        rocaucs.append(metrics.roc_auc_score(y_test, y_pred))\n",
    "        accuracies.append(metrics.accuracy_score(y_test, y_pred))\n",
    "        avg_prcs.append(metrics.average_precision_score(y_test, y_pred))\n",
    "    dataset = pd.concat(frames)\n",
    "    X = np.nan_to_num(np.array(dataset[list(set(dataset.columns) - set(['y', 'Edges']))]).astype('float32'))\n",
    "    y = np.array(dataset['y'])\n",
    "    rf = svm.SVC(kernel = 'poly', class_weight = 'auto')\n",
    "    #print cross_validation.cross_val_score(rf, X, y = y, n_jobs = -1)\n",
    "    print 'mean infos:'\n",
    "    print 'mean F1:', np.mean(f1s)\n",
    "    print 'mean precision:', np.mean(precisions)\n",
    "    print 'mean recall:', np.mean(recalls)\n",
    "    print 'mean roc_auc:', np.mean(rocaucs)\n",
    "    print 'mean accuracy:', np.mean(accuracies)\n",
    "    print 'mean avg_precision:', np.mean(avg_prcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_folds_test(nx.karate_club_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
